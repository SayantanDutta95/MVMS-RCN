Namespace(arch='Uformer_B', att_se=False, batch_size=16, checkpoint=50, dataset='CT', dd_in=1, distribute=False, distribute_mode='DDP', embed_dim=32, env='_', eval_workers=4, global_skip=False, gpu='1', local_rank=-1, local_skip=False, lr_initial=0.0002, mode='denoising', modulator=False, nepoch=250, norm_layer='nn.LayerNorm', optimizer='adamw', pretrain_weights='./log/Uformer_B/models/model_best.pth', resume=False, save_dir='./logs/', save_images=False, step_lr=50, token_mlp='leff', token_projection='linear', train_dir='../../result/', train_ps=128, train_workers=4, val_dir='../../result/', val_ps=128, vit_depth=12, vit_dim=256, vit_mlp_dim=512, vit_nheads=8, vit_patch_size=16, vit_share=False, warmup=False, warmup_epochs=3, weight_decay=0.02, win_size=8)
Uformer(
  embed_dim=32, token_projection=linear, token_mlp=leff,win_size=8
  (pos_drop): Dropout(p=0.0, inplace=False)
  (input_proj): InputProj(
    (proj): Sequential(
      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
  (output_proj): OutputProj(
    (proj): Sequential(
      (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (encoderlayer_0): BasicUformerLayer(
    dim=32, input_resolution=(128, 128), depth=1
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=32, input_resolution=(128, 128), num_heads=1, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=32, win_size=(8, 8), num_heads=1
          (qkv): LinearProjection(
            (to_q): Linear(in_features=32, out_features=32, bias=True)
            (to_kv): Linear(in_features=32, out_features=64, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=32, out_features=32, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=32, out_features=128, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=128, out_features=32, bias=True)
          )
          (eca): Identity()
        )
      )
    )
  )
  (dowsample_0): Downsample(
    (conv): Sequential(
      (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (encoderlayer_1): BasicUformerLayer(
    dim=64, input_resolution=(64, 64), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=64, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=64, win_size=(8, 8), num_heads=2
          (qkv): LinearProjection(
            (to_q): Linear(in_features=64, out_features=64, bias=True)
            (to_kv): Linear(in_features=64, out_features=128, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.006)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=64, out_features=256, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
          )
          (eca): Identity()
        )
      )
      (1): LeWinTransformerBlock(
        dim=64, input_resolution=(64, 64), num_heads=2, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=64, win_size=(8, 8), num_heads=2
          (qkv): LinearProjection(
            (to_q): Linear(in_features=64, out_features=64, bias=True)
            (to_kv): Linear(in_features=64, out_features=128, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.011)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=64, out_features=256, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
          )
          (eca): Identity()
        )
      )
    )
  )
  (dowsample_1): Downsample(
    (conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (encoderlayer_2): BasicUformerLayer(
    dim=128, input_resolution=(32, 32), depth=8
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=128, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.017)
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
          (eca): Identity()
        )
      )
      (1): LeWinTransformerBlock(
        dim=128, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.022)
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
          (eca): Identity()
        )
      )
      (2): LeWinTransformerBlock(
        dim=128, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.028)
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
          (eca): Identity()
        )
      )
      (3): LeWinTransformerBlock(
        dim=128, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.033)
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
          (eca): Identity()
        )
      )
      (4): LeWinTransformerBlock(
        dim=128, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.039)
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
          (eca): Identity()
        )
      )
      (5): LeWinTransformerBlock(
        dim=128, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.044)
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
          (eca): Identity()
        )
      )
      (6): LeWinTransformerBlock(
        dim=128, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.050)
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
          (eca): Identity()
        )
      )
      (7): LeWinTransformerBlock(
        dim=128, input_resolution=(32, 32), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.056)
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
          (eca): Identity()
        )
      )
    )
  )
  (dowsample_2): Downsample(
    (conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (encoderlayer_3): BasicUformerLayer(
    dim=256, input_resolution=(16, 16), depth=8
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=256, input_resolution=(16, 16), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.061)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
          (eca): Identity()
        )
      )
      (1): LeWinTransformerBlock(
        dim=256, input_resolution=(16, 16), num_heads=8, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.067)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
          (eca): Identity()
        )
      )
      (2): LeWinTransformerBlock(
        dim=256, input_resolution=(16, 16), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.072)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
          (eca): Identity()
        )
      )
      (3): LeWinTransformerBlock(
        dim=256, input_resolution=(16, 16), num_heads=8, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.078)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
          (eca): Identity()
        )
      )
      (4): LeWinTransformerBlock(
        dim=256, input_resolution=(16, 16), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.083)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
          (eca): Identity()
        )
      )
      (5): LeWinTransformerBlock(
        dim=256, input_resolution=(16, 16), num_heads=8, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.089)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
          (eca): Identity()
        )
      )
      (6): LeWinTransformerBlock(
        dim=256, input_resolution=(16, 16), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.094)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
          (eca): Identity()
        )
      )
      (7): LeWinTransformerBlock(
        dim=256, input_resolution=(16, 16), num_heads=8, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.100)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
          (eca): Identity()
        )
      )
    )
  )
  (dowsample_3): Downsample(
    (conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (conv): BasicUformerLayer(
    dim=512, input_resolution=(8, 8), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=512, input_resolution=(8, 8), num_heads=16, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=512, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=512, out_features=512, bias=True)
            (to_kv): Linear(in_features=512, out_features=1024, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.100)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=512, out_features=2048, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=2048, out_features=512, bias=True)
          )
          (eca): Identity()
        )
      )
      (1): LeWinTransformerBlock(
        dim=512, input_resolution=(8, 8), num_heads=16, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=None
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=512, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=512, out_features=512, bias=True)
            (to_kv): Linear(in_features=512, out_features=1024, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.100)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=512, out_features=2048, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=2048, out_features=512, bias=True)
          )
          (eca): Identity()
        )
      )
    )
  )
  (upsample_0): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (decoderlayer_0): BasicUformerLayer(
    dim=512, input_resolution=(16, 16), depth=8
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=512, input_resolution=(16, 16), num_heads=16, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=Embedding(64, 512)
        (modulator): Embedding(64, 512)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=512, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=512, out_features=512, bias=True)
            (to_kv): Linear(in_features=512, out_features=1024, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.100)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=512, out_features=2048, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=2048, out_features=512, bias=True)
          )
          (eca): Identity()
        )
      )
      (1): LeWinTransformerBlock(
        dim=512, input_resolution=(16, 16), num_heads=16, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=Embedding(64, 512)
        (modulator): Embedding(64, 512)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=512, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=512, out_features=512, bias=True)
            (to_kv): Linear(in_features=512, out_features=1024, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.094)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=512, out_features=2048, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=2048, out_features=512, bias=True)
          )
          (eca): Identity()
        )
      )
      (2): LeWinTransformerBlock(
        dim=512, input_resolution=(16, 16), num_heads=16, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=Embedding(64, 512)
        (modulator): Embedding(64, 512)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=512, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=512, out_features=512, bias=True)
            (to_kv): Linear(in_features=512, out_features=1024, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.089)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=512, out_features=2048, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=2048, out_features=512, bias=True)
          )
          (eca): Identity()
        )
      )
      (3): LeWinTransformerBlock(
        dim=512, input_resolution=(16, 16), num_heads=16, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=Embedding(64, 512)
        (modulator): Embedding(64, 512)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=512, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=512, out_features=512, bias=True)
            (to_kv): Linear(in_features=512, out_features=1024, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.083)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=512, out_features=2048, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=2048, out_features=512, bias=True)
          )
          (eca): Identity()
        )
      )
      (4): LeWinTransformerBlock(
        dim=512, input_resolution=(16, 16), num_heads=16, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=Embedding(64, 512)
        (modulator): Embedding(64, 512)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=512, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=512, out_features=512, bias=True)
            (to_kv): Linear(in_features=512, out_features=1024, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.078)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=512, out_features=2048, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=2048, out_features=512, bias=True)
          )
          (eca): Identity()
        )
      )
      (5): LeWinTransformerBlock(
        dim=512, input_resolution=(16, 16), num_heads=16, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=Embedding(64, 512)
        (modulator): Embedding(64, 512)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=512, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=512, out_features=512, bias=True)
            (to_kv): Linear(in_features=512, out_features=1024, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.072)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=512, out_features=2048, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=2048, out_features=512, bias=True)
          )
          (eca): Identity()
        )
      )
      (6): LeWinTransformerBlock(
        dim=512, input_resolution=(16, 16), num_heads=16, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=Embedding(64, 512)
        (modulator): Embedding(64, 512)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=512, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=512, out_features=512, bias=True)
            (to_kv): Linear(in_features=512, out_features=1024, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.067)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=512, out_features=2048, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=2048, out_features=512, bias=True)
          )
          (eca): Identity()
        )
      )
      (7): LeWinTransformerBlock(
        dim=512, input_resolution=(16, 16), num_heads=16, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=Embedding(64, 512)
        (modulator): Embedding(64, 512)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=512, win_size=(8, 8), num_heads=16
          (qkv): LinearProjection(
            (to_q): Linear(in_features=512, out_features=512, bias=True)
            (to_kv): Linear(in_features=512, out_features=1024, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.061)
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=512, out_features=2048, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=2048, out_features=512, bias=True)
          )
          (eca): Identity()
        )
      )
    )
  )
  (upsample_1): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(512, 128, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (decoderlayer_1): BasicUformerLayer(
    dim=256, input_resolution=(32, 32), depth=8
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=256, input_resolution=(32, 32), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=Embedding(64, 256)
        (modulator): Embedding(64, 256)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.056)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
          (eca): Identity()
        )
      )
      (1): LeWinTransformerBlock(
        dim=256, input_resolution=(32, 32), num_heads=8, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=Embedding(64, 256)
        (modulator): Embedding(64, 256)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.050)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
          (eca): Identity()
        )
      )
      (2): LeWinTransformerBlock(
        dim=256, input_resolution=(32, 32), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=Embedding(64, 256)
        (modulator): Embedding(64, 256)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.044)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
          (eca): Identity()
        )
      )
      (3): LeWinTransformerBlock(
        dim=256, input_resolution=(32, 32), num_heads=8, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=Embedding(64, 256)
        (modulator): Embedding(64, 256)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.039)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
          (eca): Identity()
        )
      )
      (4): LeWinTransformerBlock(
        dim=256, input_resolution=(32, 32), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=Embedding(64, 256)
        (modulator): Embedding(64, 256)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.033)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
          (eca): Identity()
        )
      )
      (5): LeWinTransformerBlock(
        dim=256, input_resolution=(32, 32), num_heads=8, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=Embedding(64, 256)
        (modulator): Embedding(64, 256)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.028)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
          (eca): Identity()
        )
      )
      (6): LeWinTransformerBlock(
        dim=256, input_resolution=(32, 32), num_heads=8, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=Embedding(64, 256)
        (modulator): Embedding(64, 256)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.022)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
          (eca): Identity()
        )
      )
      (7): LeWinTransformerBlock(
        dim=256, input_resolution=(32, 32), num_heads=8, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=Embedding(64, 256)
        (modulator): Embedding(64, 256)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=256, win_size=(8, 8), num_heads=8
          (qkv): LinearProjection(
            (to_q): Linear(in_features=256, out_features=256, bias=True)
            (to_kv): Linear(in_features=256, out_features=512, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.017)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=1024, out_features=256, bias=True)
          )
          (eca): Identity()
        )
      )
    )
  )
  (upsample_2): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (decoderlayer_2): BasicUformerLayer(
    dim=128, input_resolution=(64, 64), depth=2
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=128, input_resolution=(64, 64), num_heads=4, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=Embedding(64, 128)
        (modulator): Embedding(64, 128)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.011)
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
          (eca): Identity()
        )
      )
      (1): LeWinTransformerBlock(
        dim=128, input_resolution=(64, 64), num_heads=4, win_size=8, shift_size=4, mlp_ratio=4.0,modulator=Embedding(64, 128)
        (modulator): Embedding(64, 128)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=128, win_size=(8, 8), num_heads=4
          (qkv): LinearProjection(
            (to_q): Linear(in_features=128, out_features=128, bias=True)
            (to_kv): Linear(in_features=128, out_features=256, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath(drop_prob=0.006)
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=128, out_features=512, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
          )
          (eca): Identity()
        )
      )
    )
  )
  (upsample_3): Upsample(
    (deconv): Sequential(
      (0): ConvTranspose2d(128, 32, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (decoderlayer_3): BasicUformerLayer(
    dim=64, input_resolution=(128, 128), depth=1
    (blocks): ModuleList(
      (0): LeWinTransformerBlock(
        dim=64, input_resolution=(128, 128), num_heads=2, win_size=8, shift_size=0, mlp_ratio=4.0,modulator=Embedding(64, 64)
        (modulator): Embedding(64, 64)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=64, win_size=(8, 8), num_heads=2
          (qkv): LinearProjection(
            (to_q): Linear(in_features=64, out_features=64, bias=True)
            (to_kv): Linear(in_features=64, out_features=128, bias=True)
          )
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlp): LeFF(
          (linear1): Sequential(
            (0): Linear(in_features=64, out_features=256, bias=True)
            (1): GELU(approximate='none')
          )
          (dwconv): Sequential(
            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            (1): GELU(approximate='none')
          )
          (linear2): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
          )
          (eca): Identity()
        )
      )
    )
  )
)
[Ep 1 it 40	 PSNR SIDD: 29.5055	] ----  [best_Ep_SIDD 1 best_it_SIDD 40 Best_PSNR_SIDD 29.5055] 
[Ep 1 it 81	 PSNR SIDD: 30.2914	] ----  [best_Ep_SIDD 1 best_it_SIDD 81 Best_PSNR_SIDD 30.2914] 
[Ep 1 it 122	 PSNR SIDD: 30.5064	] ----  [best_Ep_SIDD 1 best_it_SIDD 122 Best_PSNR_SIDD 30.5064] 
[Ep 1 it 163	 PSNR SIDD: 30.7832	] ----  [best_Ep_SIDD 1 best_it_SIDD 163 Best_PSNR_SIDD 30.7832] 
Epoch: 1	Time: 170.0532	Loss: 4.4178	LearningRate 0.000200
[Ep 2 it 40	 PSNR SIDD: 30.9749	] ----  [best_Ep_SIDD 2 best_it_SIDD 40 Best_PSNR_SIDD 30.9749] 
[Ep 2 it 81	 PSNR SIDD: 31.2955	] ----  [best_Ep_SIDD 2 best_it_SIDD 81 Best_PSNR_SIDD 31.2955] 
[Ep 2 it 122	 PSNR SIDD: 31.5884	] ----  [best_Ep_SIDD 2 best_it_SIDD 122 Best_PSNR_SIDD 31.5884] 
[Ep 2 it 163	 PSNR SIDD: 31.7422	] ----  [best_Ep_SIDD 2 best_it_SIDD 163 Best_PSNR_SIDD 31.7422] 
Epoch: 2	Time: 175.0227	Loss: 2.7219	LearningRate 0.000200
[Ep 3 it 40	 PSNR SIDD: 31.6965	] ----  [best_Ep_SIDD 2 best_it_SIDD 163 Best_PSNR_SIDD 31.7422] 
[Ep 3 it 81	 PSNR SIDD: 31.7353	] ----  [best_Ep_SIDD 2 best_it_SIDD 163 Best_PSNR_SIDD 31.7422] 
[Ep 3 it 122	 PSNR SIDD: 31.9664	] ----  [best_Ep_SIDD 3 best_it_SIDD 122 Best_PSNR_SIDD 31.9664] 
[Ep 3 it 163	 PSNR SIDD: 32.0050	] ----  [best_Ep_SIDD 3 best_it_SIDD 163 Best_PSNR_SIDD 32.0050] 
Epoch: 3	Time: 160.5516	Loss: 2.4510	LearningRate 0.000200
[Ep 4 it 40	 PSNR SIDD: 31.9378	] ----  [best_Ep_SIDD 3 best_it_SIDD 163 Best_PSNR_SIDD 32.0050] 
[Ep 4 it 81	 PSNR SIDD: 32.0436	] ----  [best_Ep_SIDD 4 best_it_SIDD 81 Best_PSNR_SIDD 32.0436] 
[Ep 4 it 122	 PSNR SIDD: 31.8983	] ----  [best_Ep_SIDD 4 best_it_SIDD 81 Best_PSNR_SIDD 32.0436] 
[Ep 4 it 163	 PSNR SIDD: 32.2422	] ----  [best_Ep_SIDD 4 best_it_SIDD 163 Best_PSNR_SIDD 32.2422] 
Epoch: 4	Time: 158.3794	Loss: 2.3364	LearningRate 0.000200
[Ep 5 it 40	 PSNR SIDD: 32.2205	] ----  [best_Ep_SIDD 4 best_it_SIDD 163 Best_PSNR_SIDD 32.2422] 
[Ep 5 it 81	 PSNR SIDD: 32.1593	] ----  [best_Ep_SIDD 4 best_it_SIDD 163 Best_PSNR_SIDD 32.2422] 
[Ep 5 it 122	 PSNR SIDD: 32.3511	] ----  [best_Ep_SIDD 5 best_it_SIDD 122 Best_PSNR_SIDD 32.3511] 
[Ep 5 it 163	 PSNR SIDD: 32.2576	] ----  [best_Ep_SIDD 5 best_it_SIDD 122 Best_PSNR_SIDD 32.3511] 
Epoch: 5	Time: 158.8538	Loss: 2.2136	LearningRate 0.000200
[Ep 6 it 40	 PSNR SIDD: 31.8320	] ----  [best_Ep_SIDD 5 best_it_SIDD 122 Best_PSNR_SIDD 32.3511] 
[Ep 6 it 81	 PSNR SIDD: 32.0948	] ----  [best_Ep_SIDD 5 best_it_SIDD 122 Best_PSNR_SIDD 32.3511] 
[Ep 6 it 122	 PSNR SIDD: 32.3144	] ----  [best_Ep_SIDD 5 best_it_SIDD 122 Best_PSNR_SIDD 32.3511] 
[Ep 6 it 163	 PSNR SIDD: 32.2744	] ----  [best_Ep_SIDD 5 best_it_SIDD 122 Best_PSNR_SIDD 32.3511] 
Epoch: 6	Time: 148.6375	Loss: 2.5102	LearningRate 0.000200
[Ep 7 it 40	 PSNR SIDD: 32.3722	] ----  [best_Ep_SIDD 7 best_it_SIDD 40 Best_PSNR_SIDD 32.3722] 
[Ep 7 it 81	 PSNR SIDD: 32.4433	] ----  [best_Ep_SIDD 7 best_it_SIDD 81 Best_PSNR_SIDD 32.4433] 
[Ep 7 it 122	 PSNR SIDD: 32.6264	] ----  [best_Ep_SIDD 7 best_it_SIDD 122 Best_PSNR_SIDD 32.6264] 
[Ep 7 it 163	 PSNR SIDD: 32.5650	] ----  [best_Ep_SIDD 7 best_it_SIDD 122 Best_PSNR_SIDD 32.6264] 
Epoch: 7	Time: 164.2438	Loss: 2.2931	LearningRate 0.000200
[Ep 8 it 40	 PSNR SIDD: 32.6008	] ----  [best_Ep_SIDD 7 best_it_SIDD 122 Best_PSNR_SIDD 32.6264] 
[Ep 8 it 81	 PSNR SIDD: 32.5775	] ----  [best_Ep_SIDD 7 best_it_SIDD 122 Best_PSNR_SIDD 32.6264] 
[Ep 8 it 122	 PSNR SIDD: 32.5498	] ----  [best_Ep_SIDD 7 best_it_SIDD 122 Best_PSNR_SIDD 32.6264] 
[Ep 8 it 163	 PSNR SIDD: 32.5703	] ----  [best_Ep_SIDD 7 best_it_SIDD 122 Best_PSNR_SIDD 32.6264] 
Epoch: 8	Time: 145.3574	Loss: 2.2118	LearningRate 0.000200
[Ep 9 it 40	 PSNR SIDD: 32.7577	] ----  [best_Ep_SIDD 9 best_it_SIDD 40 Best_PSNR_SIDD 32.7577] 
[Ep 9 it 81	 PSNR SIDD: 32.7328	] ----  [best_Ep_SIDD 9 best_it_SIDD 40 Best_PSNR_SIDD 32.7577] 
[Ep 9 it 122	 PSNR SIDD: 32.8504	] ----  [best_Ep_SIDD 9 best_it_SIDD 122 Best_PSNR_SIDD 32.8504] 
[Ep 9 it 163	 PSNR SIDD: 32.7911	] ----  [best_Ep_SIDD 9 best_it_SIDD 122 Best_PSNR_SIDD 32.8504] 
Epoch: 9	Time: 163.4055	Loss: 2.2047	LearningRate 0.000200
[Ep 10 it 40	 PSNR SIDD: 32.7620	] ----  [best_Ep_SIDD 9 best_it_SIDD 122 Best_PSNR_SIDD 32.8504] 
[Ep 10 it 81	 PSNR SIDD: 32.6844	] ----  [best_Ep_SIDD 9 best_it_SIDD 122 Best_PSNR_SIDD 32.8504] 
[Ep 10 it 122	 PSNR SIDD: 32.7719	] ----  [best_Ep_SIDD 9 best_it_SIDD 122 Best_PSNR_SIDD 32.8504] 
[Ep 10 it 163	 PSNR SIDD: 32.8734	] ----  [best_Ep_SIDD 10 best_it_SIDD 163 Best_PSNR_SIDD 32.8734] 
Epoch: 10	Time: 156.0960	Loss: 2.1695	LearningRate 0.000200
[Ep 11 it 40	 PSNR SIDD: 32.7515	] ----  [best_Ep_SIDD 10 best_it_SIDD 163 Best_PSNR_SIDD 32.8734] 
[Ep 11 it 81	 PSNR SIDD: 32.8594	] ----  [best_Ep_SIDD 10 best_it_SIDD 163 Best_PSNR_SIDD 32.8734] 
[Ep 11 it 122	 PSNR SIDD: 32.8707	] ----  [best_Ep_SIDD 10 best_it_SIDD 163 Best_PSNR_SIDD 32.8734] 
[Ep 11 it 163	 PSNR SIDD: 32.7368	] ----  [best_Ep_SIDD 10 best_it_SIDD 163 Best_PSNR_SIDD 32.8734] 
Epoch: 11	Time: 147.9233	Loss: 2.1767	LearningRate 0.000200
[Ep 12 it 40	 PSNR SIDD: 32.8963	] ----  [best_Ep_SIDD 12 best_it_SIDD 40 Best_PSNR_SIDD 32.8963] 
[Ep 12 it 81	 PSNR SIDD: 33.0223	] ----  [best_Ep_SIDD 12 best_it_SIDD 81 Best_PSNR_SIDD 33.0223] 
[Ep 12 it 122	 PSNR SIDD: 32.9927	] ----  [best_Ep_SIDD 12 best_it_SIDD 81 Best_PSNR_SIDD 33.0223] 
[Ep 12 it 163	 PSNR SIDD: 32.8826	] ----  [best_Ep_SIDD 12 best_it_SIDD 81 Best_PSNR_SIDD 33.0223] 
Epoch: 12	Time: 161.8448	Loss: 2.1126	LearningRate 0.000200
[Ep 13 it 40	 PSNR SIDD: 33.0294	] ----  [best_Ep_SIDD 13 best_it_SIDD 40 Best_PSNR_SIDD 33.0294] 
[Ep 13 it 81	 PSNR SIDD: 32.9814	] ----  [best_Ep_SIDD 13 best_it_SIDD 40 Best_PSNR_SIDD 33.0294] 
[Ep 13 it 122	 PSNR SIDD: 32.9762	] ----  [best_Ep_SIDD 13 best_it_SIDD 40 Best_PSNR_SIDD 33.0294] 
[Ep 13 it 163	 PSNR SIDD: 33.1816	] ----  [best_Ep_SIDD 13 best_it_SIDD 163 Best_PSNR_SIDD 33.1816] 
Epoch: 13	Time: 159.5887	Loss: 2.1036	LearningRate 0.000200
[Ep 14 it 40	 PSNR SIDD: 33.2220	] ----  [best_Ep_SIDD 14 best_it_SIDD 40 Best_PSNR_SIDD 33.2220] 
[Ep 14 it 81	 PSNR SIDD: 33.1341	] ----  [best_Ep_SIDD 14 best_it_SIDD 40 Best_PSNR_SIDD 33.2220] 
[Ep 14 it 122	 PSNR SIDD: 33.1153	] ----  [best_Ep_SIDD 14 best_it_SIDD 40 Best_PSNR_SIDD 33.2220] 
[Ep 14 it 163	 PSNR SIDD: 33.1779	] ----  [best_Ep_SIDD 14 best_it_SIDD 40 Best_PSNR_SIDD 33.2220] 
Epoch: 14	Time: 157.7001	Loss: 2.0901	LearningRate 0.000200
[Ep 15 it 40	 PSNR SIDD: 33.2074	] ----  [best_Ep_SIDD 14 best_it_SIDD 40 Best_PSNR_SIDD 33.2220] 
[Ep 15 it 81	 PSNR SIDD: 33.2252	] ----  [best_Ep_SIDD 15 best_it_SIDD 81 Best_PSNR_SIDD 33.2252] 
[Ep 15 it 122	 PSNR SIDD: 33.2646	] ----  [best_Ep_SIDD 15 best_it_SIDD 122 Best_PSNR_SIDD 33.2646] 
[Ep 15 it 163	 PSNR SIDD: 33.3249	] ----  [best_Ep_SIDD 15 best_it_SIDD 163 Best_PSNR_SIDD 33.3249] 
Epoch: 15	Time: 168.2740	Loss: 2.0506	LearningRate 0.000200
[Ep 16 it 40	 PSNR SIDD: 33.4155	] ----  [best_Ep_SIDD 16 best_it_SIDD 40 Best_PSNR_SIDD 33.4155] 
[Ep 16 it 81	 PSNR SIDD: 33.3444	] ----  [best_Ep_SIDD 16 best_it_SIDD 40 Best_PSNR_SIDD 33.4155] 
[Ep 16 it 122	 PSNR SIDD: 33.3219	] ----  [best_Ep_SIDD 16 best_it_SIDD 40 Best_PSNR_SIDD 33.4155] 
[Ep 16 it 163	 PSNR SIDD: 33.3959	] ----  [best_Ep_SIDD 16 best_it_SIDD 40 Best_PSNR_SIDD 33.4155] 
Epoch: 16	Time: 151.7565	Loss: 2.0423	LearningRate 0.000200
[Ep 17 it 40	 PSNR SIDD: 33.4468	] ----  [best_Ep_SIDD 17 best_it_SIDD 40 Best_PSNR_SIDD 33.4468] 
[Ep 17 it 81	 PSNR SIDD: 33.3392	] ----  [best_Ep_SIDD 17 best_it_SIDD 40 Best_PSNR_SIDD 33.4468] 
[Ep 17 it 122	 PSNR SIDD: 33.6408	] ----  [best_Ep_SIDD 17 best_it_SIDD 122 Best_PSNR_SIDD 33.6408] 
[Ep 17 it 163	 PSNR SIDD: 33.6840	] ----  [best_Ep_SIDD 17 best_it_SIDD 163 Best_PSNR_SIDD 33.6840] 
Epoch: 17	Time: 164.9507	Loss: 2.0507	LearningRate 0.000200
[Ep 18 it 40	 PSNR SIDD: 33.5993	] ----  [best_Ep_SIDD 17 best_it_SIDD 163 Best_PSNR_SIDD 33.6840] 
[Ep 18 it 81	 PSNR SIDD: 33.5144	] ----  [best_Ep_SIDD 17 best_it_SIDD 163 Best_PSNR_SIDD 33.6840] 
[Ep 18 it 122	 PSNR SIDD: 33.4933	] ----  [best_Ep_SIDD 17 best_it_SIDD 163 Best_PSNR_SIDD 33.6840] 
[Ep 18 it 163	 PSNR SIDD: 33.7709	] ----  [best_Ep_SIDD 18 best_it_SIDD 163 Best_PSNR_SIDD 33.7709] 
Epoch: 18	Time: 151.7657	Loss: 2.0290	LearningRate 0.000200
[Ep 19 it 40	 PSNR SIDD: 33.5683	] ----  [best_Ep_SIDD 18 best_it_SIDD 163 Best_PSNR_SIDD 33.7709] 
[Ep 19 it 81	 PSNR SIDD: 33.8521	] ----  [best_Ep_SIDD 19 best_it_SIDD 81 Best_PSNR_SIDD 33.8521] 
[Ep 19 it 122	 PSNR SIDD: 33.8953	] ----  [best_Ep_SIDD 19 best_it_SIDD 122 Best_PSNR_SIDD 33.8953] 
[Ep 19 it 163	 PSNR SIDD: 34.0178	] ----  [best_Ep_SIDD 19 best_it_SIDD 163 Best_PSNR_SIDD 34.0178] 
Epoch: 19	Time: 164.6299	Loss: 1.9814	LearningRate 0.000200
[Ep 20 it 40	 PSNR SIDD: 34.0367	] ----  [best_Ep_SIDD 20 best_it_SIDD 40 Best_PSNR_SIDD 34.0367] 
[Ep 20 it 81	 PSNR SIDD: 33.8799	] ----  [best_Ep_SIDD 20 best_it_SIDD 40 Best_PSNR_SIDD 34.0367] 
[Ep 20 it 122	 PSNR SIDD: 34.0141	] ----  [best_Ep_SIDD 20 best_it_SIDD 40 Best_PSNR_SIDD 34.0367] 
[Ep 20 it 163	 PSNR SIDD: 34.0865	] ----  [best_Ep_SIDD 20 best_it_SIDD 163 Best_PSNR_SIDD 34.0865] 
Epoch: 20	Time: 168.8024	Loss: 1.9592	LearningRate 0.000200
[Ep 21 it 40	 PSNR SIDD: 34.0698	] ----  [best_Ep_SIDD 20 best_it_SIDD 163 Best_PSNR_SIDD 34.0865] 
[Ep 21 it 81	 PSNR SIDD: 34.1173	] ----  [best_Ep_SIDD 21 best_it_SIDD 81 Best_PSNR_SIDD 34.1173] 
[Ep 21 it 122	 PSNR SIDD: 34.0581	] ----  [best_Ep_SIDD 21 best_it_SIDD 81 Best_PSNR_SIDD 34.1173] 
[Ep 21 it 163	 PSNR SIDD: 33.8051	] ----  [best_Ep_SIDD 21 best_it_SIDD 81 Best_PSNR_SIDD 34.1173] 
Epoch: 21	Time: 156.4116	Loss: 1.9847	LearningRate 0.000200
[Ep 22 it 40	 PSNR SIDD: 34.3492	] ----  [best_Ep_SIDD 22 best_it_SIDD 40 Best_PSNR_SIDD 34.3492] 
[Ep 22 it 81	 PSNR SIDD: 34.2847	] ----  [best_Ep_SIDD 22 best_it_SIDD 40 Best_PSNR_SIDD 34.3492] 
[Ep 22 it 122	 PSNR SIDD: 34.2623	] ----  [best_Ep_SIDD 22 best_it_SIDD 40 Best_PSNR_SIDD 34.3492] 
[Ep 22 it 163	 PSNR SIDD: 34.3391	] ----  [best_Ep_SIDD 22 best_it_SIDD 40 Best_PSNR_SIDD 34.3492] 
Epoch: 22	Time: 160.3315	Loss: 1.9446	LearningRate 0.000200
[Ep 23 it 40	 PSNR SIDD: 34.2138	] ----  [best_Ep_SIDD 22 best_it_SIDD 40 Best_PSNR_SIDD 34.3492] 
[Ep 23 it 81	 PSNR SIDD: 34.1564	] ----  [best_Ep_SIDD 22 best_it_SIDD 40 Best_PSNR_SIDD 34.3492] 
[Ep 23 it 122	 PSNR SIDD: 34.3374	] ----  [best_Ep_SIDD 22 best_it_SIDD 40 Best_PSNR_SIDD 34.3492] 
[Ep 23 it 163	 PSNR SIDD: 34.5420	] ----  [best_Ep_SIDD 23 best_it_SIDD 163 Best_PSNR_SIDD 34.5420] 
Epoch: 23	Time: 152.2446	Loss: 1.9526	LearningRate 0.000200
[Ep 24 it 40	 PSNR SIDD: 34.4028	] ----  [best_Ep_SIDD 23 best_it_SIDD 163 Best_PSNR_SIDD 34.5420] 
[Ep 24 it 81	 PSNR SIDD: 34.5424	] ----  [best_Ep_SIDD 24 best_it_SIDD 81 Best_PSNR_SIDD 34.5424] 
[Ep 24 it 122	 PSNR SIDD: 34.5106	] ----  [best_Ep_SIDD 24 best_it_SIDD 81 Best_PSNR_SIDD 34.5424] 
[Ep 24 it 163	 PSNR SIDD: 34.3809	] ----  [best_Ep_SIDD 24 best_it_SIDD 81 Best_PSNR_SIDD 34.5424] 
Epoch: 24	Time: 152.0371	Loss: 1.9519	LearningRate 0.000200
[Ep 25 it 40	 PSNR SIDD: 34.4151	] ----  [best_Ep_SIDD 24 best_it_SIDD 81 Best_PSNR_SIDD 34.5424] 
[Ep 25 it 81	 PSNR SIDD: 34.6283	] ----  [best_Ep_SIDD 25 best_it_SIDD 81 Best_PSNR_SIDD 34.6283] 
[Ep 25 it 122	 PSNR SIDD: 34.6071	] ----  [best_Ep_SIDD 25 best_it_SIDD 81 Best_PSNR_SIDD 34.6283] 
[Ep 25 it 163	 PSNR SIDD: 34.4549	] ----  [best_Ep_SIDD 25 best_it_SIDD 81 Best_PSNR_SIDD 34.6283] 
Epoch: 25	Time: 153.9452	Loss: 1.9200	LearningRate 0.000200
[Ep 26 it 40	 PSNR SIDD: 34.5763	] ----  [best_Ep_SIDD 25 best_it_SIDD 81 Best_PSNR_SIDD 34.6283] 
[Ep 26 it 81	 PSNR SIDD: 34.6540	] ----  [best_Ep_SIDD 26 best_it_SIDD 81 Best_PSNR_SIDD 34.6540] 
[Ep 26 it 122	 PSNR SIDD: 34.6133	] ----  [best_Ep_SIDD 26 best_it_SIDD 81 Best_PSNR_SIDD 34.6540] 
[Ep 26 it 163	 PSNR SIDD: 34.6941	] ----  [best_Ep_SIDD 26 best_it_SIDD 163 Best_PSNR_SIDD 34.6941] 
Epoch: 26	Time: 161.4557	Loss: 1.9205	LearningRate 0.000200
[Ep 27 it 40	 PSNR SIDD: 34.8492	] ----  [best_Ep_SIDD 27 best_it_SIDD 40 Best_PSNR_SIDD 34.8492] 
[Ep 27 it 81	 PSNR SIDD: 34.8587	] ----  [best_Ep_SIDD 27 best_it_SIDD 81 Best_PSNR_SIDD 34.8587] 
[Ep 27 it 122	 PSNR SIDD: 34.8356	] ----  [best_Ep_SIDD 27 best_it_SIDD 81 Best_PSNR_SIDD 34.8587] 
[Ep 27 it 163	 PSNR SIDD: 34.7888	] ----  [best_Ep_SIDD 27 best_it_SIDD 81 Best_PSNR_SIDD 34.8587] 
Epoch: 27	Time: 159.7892	Loss: 1.9124	LearningRate 0.000200
[Ep 28 it 40	 PSNR SIDD: 34.8856	] ----  [best_Ep_SIDD 28 best_it_SIDD 40 Best_PSNR_SIDD 34.8856] 
[Ep 28 it 81	 PSNR SIDD: 34.9217	] ----  [best_Ep_SIDD 28 best_it_SIDD 81 Best_PSNR_SIDD 34.9217] 
[Ep 28 it 122	 PSNR SIDD: 34.9239	] ----  [best_Ep_SIDD 28 best_it_SIDD 122 Best_PSNR_SIDD 34.9239] 
[Ep 28 it 163	 PSNR SIDD: 34.8863	] ----  [best_Ep_SIDD 28 best_it_SIDD 122 Best_PSNR_SIDD 34.9239] 
Epoch: 28	Time: 164.4225	Loss: 1.8802	LearningRate 0.000200
[Ep 29 it 40	 PSNR SIDD: 34.8527	] ----  [best_Ep_SIDD 28 best_it_SIDD 122 Best_PSNR_SIDD 34.9239] 
[Ep 29 it 81	 PSNR SIDD: 35.0112	] ----  [best_Ep_SIDD 29 best_it_SIDD 81 Best_PSNR_SIDD 35.0112] 
[Ep 29 it 122	 PSNR SIDD: 35.0061	] ----  [best_Ep_SIDD 29 best_it_SIDD 81 Best_PSNR_SIDD 35.0112] 
[Ep 29 it 163	 PSNR SIDD: 34.9536	] ----  [best_Ep_SIDD 29 best_it_SIDD 81 Best_PSNR_SIDD 35.0112] 
Epoch: 29	Time: 153.5086	Loss: 1.8962	LearningRate 0.000200
[Ep 30 it 40	 PSNR SIDD: 34.9883	] ----  [best_Ep_SIDD 29 best_it_SIDD 81 Best_PSNR_SIDD 35.0112] 
[Ep 30 it 81	 PSNR SIDD: 34.9158	] ----  [best_Ep_SIDD 29 best_it_SIDD 81 Best_PSNR_SIDD 35.0112] 
[Ep 30 it 122	 PSNR SIDD: 34.9774	] ----  [best_Ep_SIDD 29 best_it_SIDD 81 Best_PSNR_SIDD 35.0112] 
[Ep 30 it 163	 PSNR SIDD: 35.0190	] ----  [best_Ep_SIDD 30 best_it_SIDD 163 Best_PSNR_SIDD 35.0190] 
Epoch: 30	Time: 155.0858	Loss: 1.8554	LearningRate 0.000200
[Ep 31 it 40	 PSNR SIDD: 35.1187	] ----  [best_Ep_SIDD 31 best_it_SIDD 40 Best_PSNR_SIDD 35.1187] 
[Ep 31 it 81	 PSNR SIDD: 34.9657	] ----  [best_Ep_SIDD 31 best_it_SIDD 40 Best_PSNR_SIDD 35.1187] 
[Ep 31 it 122	 PSNR SIDD: 35.0777	] ----  [best_Ep_SIDD 31 best_it_SIDD 40 Best_PSNR_SIDD 35.1187] 
[Ep 31 it 163	 PSNR SIDD: 34.9830	] ----  [best_Ep_SIDD 31 best_it_SIDD 40 Best_PSNR_SIDD 35.1187] 
Epoch: 31	Time: 156.0237	Loss: 1.8665	LearningRate 0.000200
[Ep 32 it 40	 PSNR SIDD: 35.1883	] ----  [best_Ep_SIDD 32 best_it_SIDD 40 Best_PSNR_SIDD 35.1883] 
[Ep 32 it 81	 PSNR SIDD: 35.2504	] ----  [best_Ep_SIDD 32 best_it_SIDD 81 Best_PSNR_SIDD 35.2504] 
[Ep 32 it 122	 PSNR SIDD: 35.1576	] ----  [best_Ep_SIDD 32 best_it_SIDD 81 Best_PSNR_SIDD 35.2504] 
[Ep 32 it 163	 PSNR SIDD: 35.1814	] ----  [best_Ep_SIDD 32 best_it_SIDD 81 Best_PSNR_SIDD 35.2504] 
Epoch: 32	Time: 160.9868	Loss: 1.8517	LearningRate 0.000200
[Ep 33 it 40	 PSNR SIDD: 35.0975	] ----  [best_Ep_SIDD 32 best_it_SIDD 81 Best_PSNR_SIDD 35.2504] 
[Ep 33 it 81	 PSNR SIDD: 34.9223	] ----  [best_Ep_SIDD 32 best_it_SIDD 81 Best_PSNR_SIDD 35.2504] 
[Ep 33 it 122	 PSNR SIDD: 34.9747	] ----  [best_Ep_SIDD 32 best_it_SIDD 81 Best_PSNR_SIDD 35.2504] 
[Ep 33 it 163	 PSNR SIDD: 35.1658	] ----  [best_Ep_SIDD 32 best_it_SIDD 81 Best_PSNR_SIDD 35.2504] 
Epoch: 33	Time: 148.5829	Loss: 1.8396	LearningRate 0.000200
[Ep 34 it 40	 PSNR SIDD: 35.2694	] ----  [best_Ep_SIDD 34 best_it_SIDD 40 Best_PSNR_SIDD 35.2694] 
[Ep 34 it 81	 PSNR SIDD: 35.1963	] ----  [best_Ep_SIDD 34 best_it_SIDD 40 Best_PSNR_SIDD 35.2694] 
[Ep 34 it 122	 PSNR SIDD: 35.2960	] ----  [best_Ep_SIDD 34 best_it_SIDD 122 Best_PSNR_SIDD 35.2960] 
[Ep 34 it 163	 PSNR SIDD: 35.1336	] ----  [best_Ep_SIDD 34 best_it_SIDD 122 Best_PSNR_SIDD 35.2960] 
Epoch: 34	Time: 159.3139	Loss: 1.8201	LearningRate 0.000200
[Ep 35 it 40	 PSNR SIDD: 35.3975	] ----  [best_Ep_SIDD 35 best_it_SIDD 40 Best_PSNR_SIDD 35.3975] 
[Ep 35 it 81	 PSNR SIDD: 35.3418	] ----  [best_Ep_SIDD 35 best_it_SIDD 40 Best_PSNR_SIDD 35.3975] 
[Ep 35 it 122	 PSNR SIDD: 34.9833	] ----  [best_Ep_SIDD 35 best_it_SIDD 40 Best_PSNR_SIDD 35.3975] 
[Ep 35 it 163	 PSNR SIDD: 35.3411	] ----  [best_Ep_SIDD 35 best_it_SIDD 40 Best_PSNR_SIDD 35.3975] 
Epoch: 35	Time: 154.9687	Loss: 1.8381	LearningRate 0.000200
[Ep 36 it 40	 PSNR SIDD: 35.3665	] ----  [best_Ep_SIDD 35 best_it_SIDD 40 Best_PSNR_SIDD 35.3975] 
[Ep 36 it 81	 PSNR SIDD: 35.3558	] ----  [best_Ep_SIDD 35 best_it_SIDD 40 Best_PSNR_SIDD 35.3975] 
[Ep 36 it 122	 PSNR SIDD: 35.2902	] ----  [best_Ep_SIDD 35 best_it_SIDD 40 Best_PSNR_SIDD 35.3975] 
[Ep 36 it 163	 PSNR SIDD: 35.3342	] ----  [best_Ep_SIDD 35 best_it_SIDD 40 Best_PSNR_SIDD 35.3975] 
Epoch: 36	Time: 146.9707	Loss: 1.8170	LearningRate 0.000200
[Ep 37 it 40	 PSNR SIDD: 35.0748	] ----  [best_Ep_SIDD 35 best_it_SIDD 40 Best_PSNR_SIDD 35.3975] 
[Ep 37 it 81	 PSNR SIDD: 35.1353	] ----  [best_Ep_SIDD 35 best_it_SIDD 40 Best_PSNR_SIDD 35.3975] 
[Ep 37 it 122	 PSNR SIDD: 35.4847	] ----  [best_Ep_SIDD 37 best_it_SIDD 122 Best_PSNR_SIDD 35.4847] 
[Ep 37 it 163	 PSNR SIDD: 35.4310	] ----  [best_Ep_SIDD 37 best_it_SIDD 122 Best_PSNR_SIDD 35.4847] 
Epoch: 37	Time: 153.7786	Loss: 1.8316	LearningRate 0.000200
[Ep 38 it 40	 PSNR SIDD: 35.3051	] ----  [best_Ep_SIDD 37 best_it_SIDD 122 Best_PSNR_SIDD 35.4847] 
[Ep 38 it 81	 PSNR SIDD: 35.3169	] ----  [best_Ep_SIDD 37 best_it_SIDD 122 Best_PSNR_SIDD 35.4847] 
[Ep 38 it 122	 PSNR SIDD: 35.4889	] ----  [best_Ep_SIDD 38 best_it_SIDD 122 Best_PSNR_SIDD 35.4889] 
[Ep 38 it 163	 PSNR SIDD: 35.6040	] ----  [best_Ep_SIDD 38 best_it_SIDD 163 Best_PSNR_SIDD 35.6040] 
Epoch: 38	Time: 158.7018	Loss: 1.8260	LearningRate 0.000200
[Ep 39 it 40	 PSNR SIDD: 35.3512	] ----  [best_Ep_SIDD 38 best_it_SIDD 163 Best_PSNR_SIDD 35.6040] 
[Ep 39 it 81	 PSNR SIDD: 35.1557	] ----  [best_Ep_SIDD 38 best_it_SIDD 163 Best_PSNR_SIDD 35.6040] 
[Ep 39 it 122	 PSNR SIDD: 35.3225	] ----  [best_Ep_SIDD 38 best_it_SIDD 163 Best_PSNR_SIDD 35.6040] 
[Ep 39 it 163	 PSNR SIDD: 35.3908	] ----  [best_Ep_SIDD 38 best_it_SIDD 163 Best_PSNR_SIDD 35.6040] 
Epoch: 39	Time: 145.7043	Loss: 1.8207	LearningRate 0.000200
[Ep 40 it 40	 PSNR SIDD: 35.3065	] ----  [best_Ep_SIDD 38 best_it_SIDD 163 Best_PSNR_SIDD 35.6040] 
[Ep 40 it 81	 PSNR SIDD: 35.4599	] ----  [best_Ep_SIDD 38 best_it_SIDD 163 Best_PSNR_SIDD 35.6040] 
[Ep 40 it 122	 PSNR SIDD: 35.4841	] ----  [best_Ep_SIDD 38 best_it_SIDD 163 Best_PSNR_SIDD 35.6040] 
[Ep 40 it 163	 PSNR SIDD: 35.5309	] ----  [best_Ep_SIDD 38 best_it_SIDD 163 Best_PSNR_SIDD 35.6040] 
Epoch: 40	Time: 145.4705	Loss: 1.7836	LearningRate 0.000200
[Ep 41 it 40	 PSNR SIDD: 35.3457	] ----  [best_Ep_SIDD 38 best_it_SIDD 163 Best_PSNR_SIDD 35.6040] 
[Ep 41 it 81	 PSNR SIDD: 35.5827	] ----  [best_Ep_SIDD 38 best_it_SIDD 163 Best_PSNR_SIDD 35.6040] 
[Ep 41 it 122	 PSNR SIDD: 35.4582	] ----  [best_Ep_SIDD 38 best_it_SIDD 163 Best_PSNR_SIDD 35.6040] 
[Ep 41 it 163	 PSNR SIDD: 35.5460	] ----  [best_Ep_SIDD 38 best_it_SIDD 163 Best_PSNR_SIDD 35.6040] 
Epoch: 41	Time: 155.1039	Loss: 1.8138	LearningRate 0.000200
[Ep 42 it 40	 PSNR SIDD: 35.6627	] ----  [best_Ep_SIDD 42 best_it_SIDD 40 Best_PSNR_SIDD 35.6627] 
[Ep 42 it 81	 PSNR SIDD: 35.5535	] ----  [best_Ep_SIDD 42 best_it_SIDD 40 Best_PSNR_SIDD 35.6627] 
[Ep 42 it 122	 PSNR SIDD: 35.6048	] ----  [best_Ep_SIDD 42 best_it_SIDD 40 Best_PSNR_SIDD 35.6627] 
[Ep 42 it 163	 PSNR SIDD: 35.6271	] ----  [best_Ep_SIDD 42 best_it_SIDD 40 Best_PSNR_SIDD 35.6627] 
Epoch: 42	Time: 156.6414	Loss: 1.8038	LearningRate 0.000200
[Ep 43 it 40	 PSNR SIDD: 35.6226	] ----  [best_Ep_SIDD 42 best_it_SIDD 40 Best_PSNR_SIDD 35.6627] 
[Ep 43 it 81	 PSNR SIDD: 35.7152	] ----  [best_Ep_SIDD 43 best_it_SIDD 81 Best_PSNR_SIDD 35.7152] 
[Ep 43 it 122	 PSNR SIDD: 35.7459	] ----  [best_Ep_SIDD 43 best_it_SIDD 122 Best_PSNR_SIDD 35.7459] 
[Ep 43 it 163	 PSNR SIDD: 35.7402	] ----  [best_Ep_SIDD 43 best_it_SIDD 122 Best_PSNR_SIDD 35.7459] 
Epoch: 43	Time: 160.0770	Loss: 1.7748	LearningRate 0.000200
[Ep 44 it 40	 PSNR SIDD: 35.7645	] ----  [best_Ep_SIDD 44 best_it_SIDD 40 Best_PSNR_SIDD 35.7645] 
[Ep 44 it 81	 PSNR SIDD: 35.7149	] ----  [best_Ep_SIDD 44 best_it_SIDD 40 Best_PSNR_SIDD 35.7645] 
[Ep 44 it 122	 PSNR SIDD: 35.5983	] ----  [best_Ep_SIDD 44 best_it_SIDD 40 Best_PSNR_SIDD 35.7645] 
[Ep 44 it 163	 PSNR SIDD: 35.7900	] ----  [best_Ep_SIDD 44 best_it_SIDD 163 Best_PSNR_SIDD 35.7900] 
Epoch: 44	Time: 159.3790	Loss: 1.7662	LearningRate 0.000200
[Ep 45 it 40	 PSNR SIDD: 35.7274	] ----  [best_Ep_SIDD 44 best_it_SIDD 163 Best_PSNR_SIDD 35.7900] 
[Ep 45 it 81	 PSNR SIDD: 35.8799	] ----  [best_Ep_SIDD 45 best_it_SIDD 81 Best_PSNR_SIDD 35.8799] 
[Ep 45 it 122	 PSNR SIDD: 35.7545	] ----  [best_Ep_SIDD 45 best_it_SIDD 81 Best_PSNR_SIDD 35.8799] 
[Ep 45 it 163	 PSNR SIDD: 35.6216	] ----  [best_Ep_SIDD 45 best_it_SIDD 81 Best_PSNR_SIDD 35.8799] 
Epoch: 45	Time: 152.7930	Loss: 1.7575	LearningRate 0.000200
[Ep 46 it 40	 PSNR SIDD: 35.7567	] ----  [best_Ep_SIDD 45 best_it_SIDD 81 Best_PSNR_SIDD 35.8799] 
[Ep 46 it 81	 PSNR SIDD: 35.6293	] ----  [best_Ep_SIDD 45 best_it_SIDD 81 Best_PSNR_SIDD 35.8799] 
[Ep 46 it 122	 PSNR SIDD: 35.8088	] ----  [best_Ep_SIDD 45 best_it_SIDD 81 Best_PSNR_SIDD 35.8799] 
[Ep 46 it 163	 PSNR SIDD: 35.8191	] ----  [best_Ep_SIDD 45 best_it_SIDD 81 Best_PSNR_SIDD 35.8799] 
Epoch: 46	Time: 149.6646	Loss: 1.7596	LearningRate 0.000200
[Ep 47 it 40	 PSNR SIDD: 35.7540	] ----  [best_Ep_SIDD 45 best_it_SIDD 81 Best_PSNR_SIDD 35.8799] 
[Ep 47 it 81	 PSNR SIDD: 35.7633	] ----  [best_Ep_SIDD 45 best_it_SIDD 81 Best_PSNR_SIDD 35.8799] 
[Ep 47 it 122	 PSNR SIDD: 35.8370	] ----  [best_Ep_SIDD 45 best_it_SIDD 81 Best_PSNR_SIDD 35.8799] 
[Ep 47 it 163	 PSNR SIDD: 35.8134	] ----  [best_Ep_SIDD 45 best_it_SIDD 81 Best_PSNR_SIDD 35.8799] 
Epoch: 47	Time: 147.6202	Loss: 1.7542	LearningRate 0.000200
[Ep 48 it 40	 PSNR SIDD: 35.7813	] ----  [best_Ep_SIDD 45 best_it_SIDD 81 Best_PSNR_SIDD 35.8799] 
[Ep 48 it 81	 PSNR SIDD: 35.7230	] ----  [best_Ep_SIDD 45 best_it_SIDD 81 Best_PSNR_SIDD 35.8799] 
[Ep 48 it 122	 PSNR SIDD: 35.8304	] ----  [best_Ep_SIDD 45 best_it_SIDD 81 Best_PSNR_SIDD 35.8799] 
[Ep 48 it 163	 PSNR SIDD: 35.8300	] ----  [best_Ep_SIDD 45 best_it_SIDD 81 Best_PSNR_SIDD 35.8799] 
Epoch: 48	Time: 146.9795	Loss: 1.7591	LearningRate 0.000200
[Ep 49 it 40	 PSNR SIDD: 35.9058	] ----  [best_Ep_SIDD 49 best_it_SIDD 40 Best_PSNR_SIDD 35.9058] 
[Ep 49 it 81	 PSNR SIDD: 35.8751	] ----  [best_Ep_SIDD 49 best_it_SIDD 40 Best_PSNR_SIDD 35.9058] 
[Ep 49 it 122	 PSNR SIDD: 35.9008	] ----  [best_Ep_SIDD 49 best_it_SIDD 40 Best_PSNR_SIDD 35.9058] 
[Ep 49 it 163	 PSNR SIDD: 35.8960	] ----  [best_Ep_SIDD 49 best_it_SIDD 40 Best_PSNR_SIDD 35.9058] 
Epoch: 49	Time: 156.3461	Loss: 1.7597	LearningRate 0.000050
[Ep 50 it 40	 PSNR SIDD: 36.1165	] ----  [best_Ep_SIDD 50 best_it_SIDD 40 Best_PSNR_SIDD 36.1165] 
[Ep 50 it 81	 PSNR SIDD: 36.0825	] ----  [best_Ep_SIDD 50 best_it_SIDD 40 Best_PSNR_SIDD 36.1165] 
[Ep 50 it 122	 PSNR SIDD: 36.1226	] ----  [best_Ep_SIDD 50 best_it_SIDD 122 Best_PSNR_SIDD 36.1226] 
[Ep 50 it 163	 PSNR SIDD: 36.0451	] ----  [best_Ep_SIDD 50 best_it_SIDD 122 Best_PSNR_SIDD 36.1226] 
Epoch: 50	Time: 159.8195	Loss: 1.6983	LearningRate 0.000100
[Ep 51 it 40	 PSNR SIDD: 36.1722	] ----  [best_Ep_SIDD 51 best_it_SIDD 40 Best_PSNR_SIDD 36.1722] 
[Ep 51 it 81	 PSNR SIDD: 36.1336	] ----  [best_Ep_SIDD 51 best_it_SIDD 40 Best_PSNR_SIDD 36.1722] 
[Ep 51 it 122	 PSNR SIDD: 36.1442	] ----  [best_Ep_SIDD 51 best_it_SIDD 40 Best_PSNR_SIDD 36.1722] 
[Ep 51 it 163	 PSNR SIDD: 36.1464	] ----  [best_Ep_SIDD 51 best_it_SIDD 40 Best_PSNR_SIDD 36.1722] 
Epoch: 51	Time: 153.4207	Loss: 1.7107	LearningRate 0.000100
[Ep 52 it 40	 PSNR SIDD: 36.1290	] ----  [best_Ep_SIDD 51 best_it_SIDD 40 Best_PSNR_SIDD 36.1722] 
[Ep 52 it 81	 PSNR SIDD: 36.1056	] ----  [best_Ep_SIDD 51 best_it_SIDD 40 Best_PSNR_SIDD 36.1722] 
[Ep 52 it 122	 PSNR SIDD: 36.1412	] ----  [best_Ep_SIDD 51 best_it_SIDD 40 Best_PSNR_SIDD 36.1722] 
[Ep 52 it 163	 PSNR SIDD: 36.0593	] ----  [best_Ep_SIDD 51 best_it_SIDD 40 Best_PSNR_SIDD 36.1722] 
Epoch: 52	Time: 145.9112	Loss: 1.6920	LearningRate 0.000100
[Ep 53 it 40	 PSNR SIDD: 36.1599	] ----  [best_Ep_SIDD 51 best_it_SIDD 40 Best_PSNR_SIDD 36.1722] 
[Ep 53 it 81	 PSNR SIDD: 36.1953	] ----  [best_Ep_SIDD 53 best_it_SIDD 81 Best_PSNR_SIDD 36.1953] 
[Ep 53 it 122	 PSNR SIDD: 36.2181	] ----  [best_Ep_SIDD 53 best_it_SIDD 122 Best_PSNR_SIDD 36.2181] 
[Ep 53 it 163	 PSNR SIDD: 36.1776	] ----  [best_Ep_SIDD 53 best_it_SIDD 122 Best_PSNR_SIDD 36.2181] 
Epoch: 53	Time: 157.9240	Loss: 1.6966	LearningRate 0.000100
[Ep 54 it 40	 PSNR SIDD: 36.2360	] ----  [best_Ep_SIDD 54 best_it_SIDD 40 Best_PSNR_SIDD 36.2360] 
[Ep 54 it 81	 PSNR SIDD: 36.2504	] ----  [best_Ep_SIDD 54 best_it_SIDD 81 Best_PSNR_SIDD 36.2504] 
[Ep 54 it 122	 PSNR SIDD: 36.2027	] ----  [best_Ep_SIDD 54 best_it_SIDD 81 Best_PSNR_SIDD 36.2504] 
[Ep 54 it 163	 PSNR SIDD: 36.2816	] ----  [best_Ep_SIDD 54 best_it_SIDD 163 Best_PSNR_SIDD 36.2816] 
Epoch: 54	Time: 172.3657	Loss: 1.7028	LearningRate 0.000100
[Ep 55 it 40	 PSNR SIDD: 36.1685	] ----  [best_Ep_SIDD 54 best_it_SIDD 163 Best_PSNR_SIDD 36.2816] 
[Ep 55 it 81	 PSNR SIDD: 36.2481	] ----  [best_Ep_SIDD 54 best_it_SIDD 163 Best_PSNR_SIDD 36.2816] 
[Ep 55 it 122	 PSNR SIDD: 36.2205	] ----  [best_Ep_SIDD 54 best_it_SIDD 163 Best_PSNR_SIDD 36.2816] 
[Ep 55 it 163	 PSNR SIDD: 36.1621	] ----  [best_Ep_SIDD 54 best_it_SIDD 163 Best_PSNR_SIDD 36.2816] 
Epoch: 55	Time: 150.0921	Loss: 1.6839	LearningRate 0.000100
[Ep 56 it 40	 PSNR SIDD: 36.2673	] ----  [best_Ep_SIDD 54 best_it_SIDD 163 Best_PSNR_SIDD 36.2816] 
[Ep 56 it 81	 PSNR SIDD: 36.1436	] ----  [best_Ep_SIDD 54 best_it_SIDD 163 Best_PSNR_SIDD 36.2816] 
[Ep 56 it 122	 PSNR SIDD: 36.3589	] ----  [best_Ep_SIDD 56 best_it_SIDD 122 Best_PSNR_SIDD 36.3589] 
[Ep 56 it 163	 PSNR SIDD: 36.2432	] ----  [best_Ep_SIDD 56 best_it_SIDD 122 Best_PSNR_SIDD 36.3589] 
Epoch: 56	Time: 153.2282	Loss: 1.6796	LearningRate 0.000100
[Ep 57 it 40	 PSNR SIDD: 36.2377	] ----  [best_Ep_SIDD 56 best_it_SIDD 122 Best_PSNR_SIDD 36.3589] 
[Ep 57 it 81	 PSNR SIDD: 36.1551	] ----  [best_Ep_SIDD 56 best_it_SIDD 122 Best_PSNR_SIDD 36.3589] 
[Ep 57 it 122	 PSNR SIDD: 36.2835	] ----  [best_Ep_SIDD 56 best_it_SIDD 122 Best_PSNR_SIDD 36.3589] 
[Ep 57 it 163	 PSNR SIDD: 36.3433	] ----  [best_Ep_SIDD 56 best_it_SIDD 122 Best_PSNR_SIDD 36.3589] 
Epoch: 57	Time: 148.2290	Loss: 1.6808	LearningRate 0.000100
[Ep 58 it 40	 PSNR SIDD: 36.0929	] ----  [best_Ep_SIDD 56 best_it_SIDD 122 Best_PSNR_SIDD 36.3589] 
[Ep 58 it 81	 PSNR SIDD: 36.1551	] ----  [best_Ep_SIDD 56 best_it_SIDD 122 Best_PSNR_SIDD 36.3589] 
[Ep 58 it 122	 PSNR SIDD: 36.2429	] ----  [best_Ep_SIDD 56 best_it_SIDD 122 Best_PSNR_SIDD 36.3589] 
[Ep 58 it 163	 PSNR SIDD: 36.2987	] ----  [best_Ep_SIDD 56 best_it_SIDD 122 Best_PSNR_SIDD 36.3589] 
Epoch: 58	Time: 146.9470	Loss: 1.7026	LearningRate 0.000100
[Ep 59 it 40	 PSNR SIDD: 36.3177	] ----  [best_Ep_SIDD 56 best_it_SIDD 122 Best_PSNR_SIDD 36.3589] 
[Ep 59 it 81	 PSNR SIDD: 36.2423	] ----  [best_Ep_SIDD 56 best_it_SIDD 122 Best_PSNR_SIDD 36.3589] 
[Ep 59 it 122	 PSNR SIDD: 36.3898	] ----  [best_Ep_SIDD 59 best_it_SIDD 122 Best_PSNR_SIDD 36.3898] 
[Ep 59 it 163	 PSNR SIDD: 36.2491	] ----  [best_Ep_SIDD 59 best_it_SIDD 122 Best_PSNR_SIDD 36.3898] 
Epoch: 59	Time: 156.2675	Loss: 1.6691	LearningRate 0.000100
[Ep 60 it 40	 PSNR SIDD: 36.2665	] ----  [best_Ep_SIDD 59 best_it_SIDD 122 Best_PSNR_SIDD 36.3898] 
[Ep 60 it 81	 PSNR SIDD: 36.2650	] ----  [best_Ep_SIDD 59 best_it_SIDD 122 Best_PSNR_SIDD 36.3898] 
[Ep 60 it 122	 PSNR SIDD: 36.1602	] ----  [best_Ep_SIDD 59 best_it_SIDD 122 Best_PSNR_SIDD 36.3898] 
[Ep 60 it 163	 PSNR SIDD: 36.3243	] ----  [best_Ep_SIDD 59 best_it_SIDD 122 Best_PSNR_SIDD 36.3898] 
Epoch: 60	Time: 148.7989	Loss: 1.6733	LearningRate 0.000100
[Ep 61 it 40	 PSNR SIDD: 36.3139	] ----  [best_Ep_SIDD 59 best_it_SIDD 122 Best_PSNR_SIDD 36.3898] 
[Ep 61 it 81	 PSNR SIDD: 36.4042	] ----  [best_Ep_SIDD 61 best_it_SIDD 81 Best_PSNR_SIDD 36.4042] 
[Ep 61 it 122	 PSNR SIDD: 36.3657	] ----  [best_Ep_SIDD 61 best_it_SIDD 81 Best_PSNR_SIDD 36.4042] 
[Ep 61 it 163	 PSNR SIDD: 36.3973	] ----  [best_Ep_SIDD 61 best_it_SIDD 81 Best_PSNR_SIDD 36.4042] 
Epoch: 61	Time: 154.5241	Loss: 1.6694	LearningRate 0.000100
[Ep 62 it 40	 PSNR SIDD: 36.3695	] ----  [best_Ep_SIDD 61 best_it_SIDD 81 Best_PSNR_SIDD 36.4042] 
[Ep 62 it 81	 PSNR SIDD: 36.3644	] ----  [best_Ep_SIDD 61 best_it_SIDD 81 Best_PSNR_SIDD 36.4042] 
[Ep 62 it 122	 PSNR SIDD: 36.4326	] ----  [best_Ep_SIDD 62 best_it_SIDD 122 Best_PSNR_SIDD 36.4326] 
[Ep 62 it 163	 PSNR SIDD: 36.3194	] ----  [best_Ep_SIDD 62 best_it_SIDD 122 Best_PSNR_SIDD 36.4326] 
Epoch: 62	Time: 153.6933	Loss: 1.6773	LearningRate 0.000100
[Ep 63 it 40	 PSNR SIDD: 36.2227	] ----  [best_Ep_SIDD 62 best_it_SIDD 122 Best_PSNR_SIDD 36.4326] 
[Ep 63 it 81	 PSNR SIDD: 36.3797	] ----  [best_Ep_SIDD 62 best_it_SIDD 122 Best_PSNR_SIDD 36.4326] 
[Ep 63 it 122	 PSNR SIDD: 36.2682	] ----  [best_Ep_SIDD 62 best_it_SIDD 122 Best_PSNR_SIDD 36.4326] 
[Ep 63 it 163	 PSNR SIDD: 36.2886	] ----  [best_Ep_SIDD 62 best_it_SIDD 122 Best_PSNR_SIDD 36.4326] 
Epoch: 63	Time: 148.5575	Loss: 1.6672	LearningRate 0.000100
[Ep 64 it 40	 PSNR SIDD: 36.3766	] ----  [best_Ep_SIDD 62 best_it_SIDD 122 Best_PSNR_SIDD 36.4326] 
[Ep 64 it 81	 PSNR SIDD: 36.4657	] ----  [best_Ep_SIDD 64 best_it_SIDD 81 Best_PSNR_SIDD 36.4657] 
[Ep 64 it 122	 PSNR SIDD: 36.3357	] ----  [best_Ep_SIDD 64 best_it_SIDD 81 Best_PSNR_SIDD 36.4657] 
[Ep 64 it 163	 PSNR SIDD: 36.4190	] ----  [best_Ep_SIDD 64 best_it_SIDD 81 Best_PSNR_SIDD 36.4657] 
Epoch: 64	Time: 155.4253	Loss: 1.6555	LearningRate 0.000100
[Ep 65 it 40	 PSNR SIDD: 36.2914	] ----  [best_Ep_SIDD 64 best_it_SIDD 81 Best_PSNR_SIDD 36.4657] 
[Ep 65 it 81	 PSNR SIDD: 36.3744	] ----  [best_Ep_SIDD 64 best_it_SIDD 81 Best_PSNR_SIDD 36.4657] 
[Ep 65 it 122	 PSNR SIDD: 36.4332	] ----  [best_Ep_SIDD 64 best_it_SIDD 81 Best_PSNR_SIDD 36.4657] 
[Ep 65 it 163	 PSNR SIDD: 36.4508	] ----  [best_Ep_SIDD 64 best_it_SIDD 81 Best_PSNR_SIDD 36.4657] 
Epoch: 65	Time: 148.3934	Loss: 1.6664	LearningRate 0.000100
[Ep 66 it 40	 PSNR SIDD: 36.4289	] ----  [best_Ep_SIDD 64 best_it_SIDD 81 Best_PSNR_SIDD 36.4657] 
[Ep 66 it 81	 PSNR SIDD: 36.3790	] ----  [best_Ep_SIDD 64 best_it_SIDD 81 Best_PSNR_SIDD 36.4657] 
[Ep 66 it 122	 PSNR SIDD: 36.4346	] ----  [best_Ep_SIDD 64 best_it_SIDD 81 Best_PSNR_SIDD 36.4657] 
[Ep 66 it 163	 PSNR SIDD: 36.3858	] ----  [best_Ep_SIDD 64 best_it_SIDD 81 Best_PSNR_SIDD 36.4657] 
Epoch: 66	Time: 145.7278	Loss: 1.6681	LearningRate 0.000100
[Ep 67 it 40	 PSNR SIDD: 36.3687	] ----  [best_Ep_SIDD 64 best_it_SIDD 81 Best_PSNR_SIDD 36.4657] 
[Ep 67 it 81	 PSNR SIDD: 36.3585	] ----  [best_Ep_SIDD 64 best_it_SIDD 81 Best_PSNR_SIDD 36.4657] 
[Ep 67 it 122	 PSNR SIDD: 36.4110	] ----  [best_Ep_SIDD 64 best_it_SIDD 81 Best_PSNR_SIDD 36.4657] 
[Ep 67 it 163	 PSNR SIDD: 36.3657	] ----  [best_Ep_SIDD 64 best_it_SIDD 81 Best_PSNR_SIDD 36.4657] 
Epoch: 67	Time: 145.3663	Loss: 1.6594	LearningRate 0.000100
[Ep 68 it 40	 PSNR SIDD: 36.3723	] ----  [best_Ep_SIDD 64 best_it_SIDD 81 Best_PSNR_SIDD 36.4657] 
[Ep 68 it 81	 PSNR SIDD: 36.2951	] ----  [best_Ep_SIDD 64 best_it_SIDD 81 Best_PSNR_SIDD 36.4657] 
[Ep 68 it 122	 PSNR SIDD: 36.5091	] ----  [best_Ep_SIDD 68 best_it_SIDD 122 Best_PSNR_SIDD 36.5091] 
[Ep 68 it 163	 PSNR SIDD: 36.4658	] ----  [best_Ep_SIDD 68 best_it_SIDD 122 Best_PSNR_SIDD 36.5091] 
Epoch: 68	Time: 152.0368	Loss: 1.6821	LearningRate 0.000100
[Ep 69 it 40	 PSNR SIDD: 36.3988	] ----  [best_Ep_SIDD 68 best_it_SIDD 122 Best_PSNR_SIDD 36.5091] 
[Ep 69 it 81	 PSNR SIDD: 36.4477	] ----  [best_Ep_SIDD 68 best_it_SIDD 122 Best_PSNR_SIDD 36.5091] 
[Ep 69 it 122	 PSNR SIDD: 36.4673	] ----  [best_Ep_SIDD 68 best_it_SIDD 122 Best_PSNR_SIDD 36.5091] 
[Ep 69 it 163	 PSNR SIDD: 36.3295	] ----  [best_Ep_SIDD 68 best_it_SIDD 122 Best_PSNR_SIDD 36.5091] 
Epoch: 69	Time: 145.4137	Loss: 1.6772	LearningRate 0.000100
[Ep 70 it 40	 PSNR SIDD: 36.4548	] ----  [best_Ep_SIDD 68 best_it_SIDD 122 Best_PSNR_SIDD 36.5091] 
[Ep 70 it 81	 PSNR SIDD: 36.5567	] ----  [best_Ep_SIDD 70 best_it_SIDD 81 Best_PSNR_SIDD 36.5567] 
[Ep 70 it 122	 PSNR SIDD: 36.4902	] ----  [best_Ep_SIDD 70 best_it_SIDD 81 Best_PSNR_SIDD 36.5567] 
[Ep 70 it 163	 PSNR SIDD: 36.5001	] ----  [best_Ep_SIDD 70 best_it_SIDD 81 Best_PSNR_SIDD 36.5567] 
Epoch: 70	Time: 151.4970	Loss: 1.6581	LearningRate 0.000100
[Ep 71 it 40	 PSNR SIDD: 36.4814	] ----  [best_Ep_SIDD 70 best_it_SIDD 81 Best_PSNR_SIDD 36.5567] 
[Ep 71 it 81	 PSNR SIDD: 36.3402	] ----  [best_Ep_SIDD 70 best_it_SIDD 81 Best_PSNR_SIDD 36.5567] 
[Ep 71 it 122	 PSNR SIDD: 36.4495	] ----  [best_Ep_SIDD 70 best_it_SIDD 81 Best_PSNR_SIDD 36.5567] 
[Ep 71 it 163	 PSNR SIDD: 36.4846	] ----  [best_Ep_SIDD 70 best_it_SIDD 81 Best_PSNR_SIDD 36.5567] 
Epoch: 71	Time: 145.2571	Loss: 1.6681	LearningRate 0.000100
[Ep 72 it 40	 PSNR SIDD: 36.4429	] ----  [best_Ep_SIDD 70 best_it_SIDD 81 Best_PSNR_SIDD 36.5567] 
[Ep 72 it 81	 PSNR SIDD: 36.5814	] ----  [best_Ep_SIDD 72 best_it_SIDD 81 Best_PSNR_SIDD 36.5814] 
[Ep 72 it 122	 PSNR SIDD: 36.5410	] ----  [best_Ep_SIDD 72 best_it_SIDD 81 Best_PSNR_SIDD 36.5814] 
[Ep 72 it 163	 PSNR SIDD: 36.5429	] ----  [best_Ep_SIDD 72 best_it_SIDD 81 Best_PSNR_SIDD 36.5814] 
Epoch: 72	Time: 151.6546	Loss: 1.6478	LearningRate 0.000100
[Ep 73 it 40	 PSNR SIDD: 36.5786	] ----  [best_Ep_SIDD 72 best_it_SIDD 81 Best_PSNR_SIDD 36.5814] 
[Ep 73 it 81	 PSNR SIDD: 36.4803	] ----  [best_Ep_SIDD 72 best_it_SIDD 81 Best_PSNR_SIDD 36.5814] 
[Ep 73 it 122	 PSNR SIDD: 36.4421	] ----  [best_Ep_SIDD 72 best_it_SIDD 81 Best_PSNR_SIDD 36.5814] 
[Ep 73 it 163	 PSNR SIDD: 36.6074	] ----  [best_Ep_SIDD 73 best_it_SIDD 163 Best_PSNR_SIDD 36.6074] 
Epoch: 73	Time: 152.4152	Loss: 1.6350	LearningRate 0.000100
[Ep 74 it 40	 PSNR SIDD: 36.3692	] ----  [best_Ep_SIDD 73 best_it_SIDD 163 Best_PSNR_SIDD 36.6074] 
[Ep 74 it 81	 PSNR SIDD: 36.5782	] ----  [best_Ep_SIDD 73 best_it_SIDD 163 Best_PSNR_SIDD 36.6074] 
[Ep 74 it 122	 PSNR SIDD: 36.5297	] ----  [best_Ep_SIDD 73 best_it_SIDD 163 Best_PSNR_SIDD 36.6074] 
[Ep 74 it 163	 PSNR SIDD: 36.4361	] ----  [best_Ep_SIDD 73 best_it_SIDD 163 Best_PSNR_SIDD 36.6074] 
Epoch: 74	Time: 145.7116	Loss: 1.6547	LearningRate 0.000100
[Ep 75 it 40	 PSNR SIDD: 36.6105	] ----  [best_Ep_SIDD 75 best_it_SIDD 40 Best_PSNR_SIDD 36.6105] 
[Ep 75 it 81	 PSNR SIDD: 36.4853	] ----  [best_Ep_SIDD 75 best_it_SIDD 40 Best_PSNR_SIDD 36.6105] 
[Ep 75 it 122	 PSNR SIDD: 36.5765	] ----  [best_Ep_SIDD 75 best_it_SIDD 40 Best_PSNR_SIDD 36.6105] 
[Ep 75 it 163	 PSNR SIDD: 36.5272	] ----  [best_Ep_SIDD 75 best_it_SIDD 40 Best_PSNR_SIDD 36.6105] 
Epoch: 75	Time: 151.7994	Loss: 1.6594	LearningRate 0.000100
[Ep 76 it 40	 PSNR SIDD: 36.5838	] ----  [best_Ep_SIDD 75 best_it_SIDD 40 Best_PSNR_SIDD 36.6105] 
[Ep 76 it 81	 PSNR SIDD: 36.5586	] ----  [best_Ep_SIDD 75 best_it_SIDD 40 Best_PSNR_SIDD 36.6105] 
[Ep 76 it 122	 PSNR SIDD: 36.3579	] ----  [best_Ep_SIDD 75 best_it_SIDD 40 Best_PSNR_SIDD 36.6105] 
[Ep 76 it 163	 PSNR SIDD: 36.4461	] ----  [best_Ep_SIDD 75 best_it_SIDD 40 Best_PSNR_SIDD 36.6105] 
Epoch: 76	Time: 145.3337	Loss: 1.6441	LearningRate 0.000100
[Ep 77 it 40	 PSNR SIDD: 36.4259	] ----  [best_Ep_SIDD 75 best_it_SIDD 40 Best_PSNR_SIDD 36.6105] 
[Ep 77 it 81	 PSNR SIDD: 36.5847	] ----  [best_Ep_SIDD 75 best_it_SIDD 40 Best_PSNR_SIDD 36.6105] 
[Ep 77 it 122	 PSNR SIDD: 36.5425	] ----  [best_Ep_SIDD 75 best_it_SIDD 40 Best_PSNR_SIDD 36.6105] 
[Ep 77 it 163	 PSNR SIDD: 36.5899	] ----  [best_Ep_SIDD 75 best_it_SIDD 40 Best_PSNR_SIDD 36.6105] 
Epoch: 77	Time: 145.6335	Loss: 1.6495	LearningRate 0.000100
[Ep 78 it 40	 PSNR SIDD: 36.5704	] ----  [best_Ep_SIDD 75 best_it_SIDD 40 Best_PSNR_SIDD 36.6105] 
[Ep 78 it 81	 PSNR SIDD: 36.6210	] ----  [best_Ep_SIDD 78 best_it_SIDD 81 Best_PSNR_SIDD 36.6210] 
[Ep 78 it 122	 PSNR SIDD: 36.5637	] ----  [best_Ep_SIDD 78 best_it_SIDD 81 Best_PSNR_SIDD 36.6210] 
[Ep 78 it 163	 PSNR SIDD: 36.6109	] ----  [best_Ep_SIDD 78 best_it_SIDD 81 Best_PSNR_SIDD 36.6210] 
Epoch: 78	Time: 151.5360	Loss: 1.6517	LearningRate 0.000100
[Ep 79 it 40	 PSNR SIDD: 36.6487	] ----  [best_Ep_SIDD 79 best_it_SIDD 40 Best_PSNR_SIDD 36.6487] 
[Ep 79 it 81	 PSNR SIDD: 36.5784	] ----  [best_Ep_SIDD 79 best_it_SIDD 40 Best_PSNR_SIDD 36.6487] 
[Ep 79 it 122	 PSNR SIDD: 36.5967	] ----  [best_Ep_SIDD 79 best_it_SIDD 40 Best_PSNR_SIDD 36.6487] 
[Ep 79 it 163	 PSNR SIDD: 36.6033	] ----  [best_Ep_SIDD 79 best_it_SIDD 40 Best_PSNR_SIDD 36.6487] 
Epoch: 79	Time: 151.4739	Loss: 1.6393	LearningRate 0.000100
[Ep 80 it 40	 PSNR SIDD: 36.4988	] ----  [best_Ep_SIDD 79 best_it_SIDD 40 Best_PSNR_SIDD 36.6487] 
[Ep 80 it 81	 PSNR SIDD: 36.5842	] ----  [best_Ep_SIDD 79 best_it_SIDD 40 Best_PSNR_SIDD 36.6487] 
[Ep 80 it 122	 PSNR SIDD: 36.7064	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
[Ep 80 it 163	 PSNR SIDD: 36.5301	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
Epoch: 80	Time: 152.1360	Loss: 1.6310	LearningRate 0.000100
[Ep 81 it 40	 PSNR SIDD: 36.5750	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
[Ep 81 it 81	 PSNR SIDD: 36.6680	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
[Ep 81 it 122	 PSNR SIDD: 36.5160	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
[Ep 81 it 163	 PSNR SIDD: 36.6447	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
Epoch: 81	Time: 145.4567	Loss: 1.6382	LearningRate 0.000100
[Ep 82 it 40	 PSNR SIDD: 36.5870	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
[Ep 82 it 81	 PSNR SIDD: 36.6159	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
[Ep 82 it 122	 PSNR SIDD: 36.5847	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
[Ep 82 it 163	 PSNR SIDD: 36.6429	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
Epoch: 82	Time: 145.6057	Loss: 1.6368	LearningRate 0.000100
[Ep 83 it 40	 PSNR SIDD: 36.7000	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
[Ep 83 it 81	 PSNR SIDD: 36.6750	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
[Ep 83 it 122	 PSNR SIDD: 36.6302	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
[Ep 83 it 163	 PSNR SIDD: 36.5326	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
Epoch: 83	Time: 145.5563	Loss: 1.6340	LearningRate 0.000100
[Ep 84 it 40	 PSNR SIDD: 36.6705	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
[Ep 84 it 81	 PSNR SIDD: 36.4790	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
[Ep 84 it 122	 PSNR SIDD: 36.6913	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
[Ep 84 it 163	 PSNR SIDD: 36.6450	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
Epoch: 84	Time: 145.4531	Loss: 1.6247	LearningRate 0.000100
[Ep 85 it 40	 PSNR SIDD: 36.5592	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
[Ep 85 it 81	 PSNR SIDD: 36.6914	] ----  [best_Ep_SIDD 80 best_it_SIDD 122 Best_PSNR_SIDD 36.7064] 
[Ep 85 it 122	 PSNR SIDD: 36.7233	] ----  [best_Ep_SIDD 85 best_it_SIDD 122 Best_PSNR_SIDD 36.7233] 
[Ep 85 it 163	 PSNR SIDD: 36.7239	] ----  [best_Ep_SIDD 85 best_it_SIDD 163 Best_PSNR_SIDD 36.7239] 
Epoch: 85	Time: 158.0018	Loss: 1.6233	LearningRate 0.000100
[Ep 86 it 40	 PSNR SIDD: 36.5898	] ----  [best_Ep_SIDD 85 best_it_SIDD 163 Best_PSNR_SIDD 36.7239] 
[Ep 86 it 81	 PSNR SIDD: 36.7094	] ----  [best_Ep_SIDD 85 best_it_SIDD 163 Best_PSNR_SIDD 36.7239] 
[Ep 86 it 122	 PSNR SIDD: 36.6610	] ----  [best_Ep_SIDD 85 best_it_SIDD 163 Best_PSNR_SIDD 36.7239] 
[Ep 86 it 163	 PSNR SIDD: 36.6773	] ----  [best_Ep_SIDD 85 best_it_SIDD 163 Best_PSNR_SIDD 36.7239] 
Epoch: 86	Time: 145.4527	Loss: 1.6321	LearningRate 0.000100
[Ep 87 it 40	 PSNR SIDD: 36.6610	] ----  [best_Ep_SIDD 85 best_it_SIDD 163 Best_PSNR_SIDD 36.7239] 
[Ep 87 it 81	 PSNR SIDD: 36.7079	] ----  [best_Ep_SIDD 85 best_it_SIDD 163 Best_PSNR_SIDD 36.7239] 
[Ep 87 it 122	 PSNR SIDD: 36.6521	] ----  [best_Ep_SIDD 85 best_it_SIDD 163 Best_PSNR_SIDD 36.7239] 
[Ep 87 it 163	 PSNR SIDD: 36.7679	] ----  [best_Ep_SIDD 87 best_it_SIDD 163 Best_PSNR_SIDD 36.7679] 
Epoch: 87	Time: 151.5119	Loss: 1.6357	LearningRate 0.000100
[Ep 88 it 40	 PSNR SIDD: 36.7719	] ----  [best_Ep_SIDD 88 best_it_SIDD 40 Best_PSNR_SIDD 36.7719] 
[Ep 88 it 81	 PSNR SIDD: 36.7437	] ----  [best_Ep_SIDD 88 best_it_SIDD 40 Best_PSNR_SIDD 36.7719] 
[Ep 88 it 122	 PSNR SIDD: 36.8352	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 88 it 163	 PSNR SIDD: 36.7400	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
Epoch: 88	Time: 157.9682	Loss: 1.6287	LearningRate 0.000100
[Ep 89 it 40	 PSNR SIDD: 36.7703	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 89 it 81	 PSNR SIDD: 36.7829	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 89 it 122	 PSNR SIDD: 36.8053	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 89 it 163	 PSNR SIDD: 36.7092	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
Epoch: 89	Time: 145.1628	Loss: 1.6236	LearningRate 0.000100
[Ep 90 it 40	 PSNR SIDD: 36.7792	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 90 it 81	 PSNR SIDD: 36.8138	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 90 it 122	 PSNR SIDD: 36.7811	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 90 it 163	 PSNR SIDD: 36.7020	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
Epoch: 90	Time: 145.4726	Loss: 1.6290	LearningRate 0.000100
[Ep 91 it 40	 PSNR SIDD: 36.7142	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 91 it 81	 PSNR SIDD: 36.7885	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 91 it 122	 PSNR SIDD: 36.7137	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 91 it 163	 PSNR SIDD: 36.7795	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
Epoch: 91	Time: 145.4131	Loss: 1.6042	LearningRate 0.000100
[Ep 92 it 40	 PSNR SIDD: 36.7687	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 92 it 81	 PSNR SIDD: 36.7512	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 92 it 122	 PSNR SIDD: 36.6230	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 92 it 163	 PSNR SIDD: 36.6252	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
Epoch: 92	Time: 145.3557	Loss: 1.6240	LearningRate 0.000100
[Ep 93 it 40	 PSNR SIDD: 36.6356	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 93 it 81	 PSNR SIDD: 36.6412	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 93 it 122	 PSNR SIDD: 36.7357	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 93 it 163	 PSNR SIDD: 36.6680	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
Epoch: 93	Time: 145.5378	Loss: 1.6118	LearningRate 0.000100
[Ep 94 it 40	 PSNR SIDD: 36.7679	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 94 it 81	 PSNR SIDD: 36.7070	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 94 it 122	 PSNR SIDD: 36.7072	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 94 it 163	 PSNR SIDD: 36.7364	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
Epoch: 94	Time: 145.4754	Loss: 1.6175	LearningRate 0.000100
[Ep 95 it 40	 PSNR SIDD: 36.7370	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 95 it 81	 PSNR SIDD: 36.7321	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 95 it 122	 PSNR SIDD: 36.4123	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 95 it 163	 PSNR SIDD: 36.7968	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
Epoch: 95	Time: 145.3403	Loss: 1.6239	LearningRate 0.000100
[Ep 96 it 40	 PSNR SIDD: 36.7113	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 96 it 81	 PSNR SIDD: 36.8316	] ----  [best_Ep_SIDD 88 best_it_SIDD 122 Best_PSNR_SIDD 36.8352] 
[Ep 96 it 122	 PSNR SIDD: 36.8381	] ----  [best_Ep_SIDD 96 best_it_SIDD 122 Best_PSNR_SIDD 36.8381] 
[Ep 96 it 163	 PSNR SIDD: 36.8614	] ----  [best_Ep_SIDD 96 best_it_SIDD 163 Best_PSNR_SIDD 36.8614] 
Epoch: 96	Time: 157.8417	Loss: 1.6273	LearningRate 0.000100
[Ep 97 it 40	 PSNR SIDD: 36.7872	] ----  [best_Ep_SIDD 96 best_it_SIDD 163 Best_PSNR_SIDD 36.8614] 
[Ep 97 it 81	 PSNR SIDD: 36.7549	] ----  [best_Ep_SIDD 96 best_it_SIDD 163 Best_PSNR_SIDD 36.8614] 
[Ep 97 it 122	 PSNR SIDD: 36.8048	] ----  [best_Ep_SIDD 96 best_it_SIDD 163 Best_PSNR_SIDD 36.8614] 
[Ep 97 it 163	 PSNR SIDD: 36.8053	] ----  [best_Ep_SIDD 96 best_it_SIDD 163 Best_PSNR_SIDD 36.8614] 
Epoch: 97	Time: 145.3528	Loss: 1.6222	LearningRate 0.000100
[Ep 98 it 40	 PSNR SIDD: 36.8517	] ----  [best_Ep_SIDD 96 best_it_SIDD 163 Best_PSNR_SIDD 36.8614] 
[Ep 98 it 81	 PSNR SIDD: 36.6893	] ----  [best_Ep_SIDD 96 best_it_SIDD 163 Best_PSNR_SIDD 36.8614] 
[Ep 98 it 122	 PSNR SIDD: 36.7301	] ----  [best_Ep_SIDD 96 best_it_SIDD 163 Best_PSNR_SIDD 36.8614] 
[Ep 98 it 163	 PSNR SIDD: 36.7807	] ----  [best_Ep_SIDD 96 best_it_SIDD 163 Best_PSNR_SIDD 36.8614] 
Epoch: 98	Time: 145.4482	Loss: 1.6176	LearningRate 0.000100
[Ep 99 it 40	 PSNR SIDD: 36.7693	] ----  [best_Ep_SIDD 96 best_it_SIDD 163 Best_PSNR_SIDD 36.8614] 
[Ep 99 it 81	 PSNR SIDD: 36.8052	] ----  [best_Ep_SIDD 96 best_it_SIDD 163 Best_PSNR_SIDD 36.8614] 
[Ep 99 it 122	 PSNR SIDD: 36.7504	] ----  [best_Ep_SIDD 96 best_it_SIDD 163 Best_PSNR_SIDD 36.8614] 
[Ep 99 it 163	 PSNR SIDD: 36.7400	] ----  [best_Ep_SIDD 96 best_it_SIDD 163 Best_PSNR_SIDD 36.8614] 
Epoch: 99	Time: 145.4625	Loss: 1.5956	LearningRate 0.000025
[Ep 100 it 40	 PSNR SIDD: 36.9506	] ----  [best_Ep_SIDD 100 best_it_SIDD 40 Best_PSNR_SIDD 36.9506] 
[Ep 100 it 81	 PSNR SIDD: 36.9593	] ----  [best_Ep_SIDD 100 best_it_SIDD 81 Best_PSNR_SIDD 36.9593] 
[Ep 100 it 122	 PSNR SIDD: 36.9383	] ----  [best_Ep_SIDD 100 best_it_SIDD 81 Best_PSNR_SIDD 36.9593] 
[Ep 100 it 163	 PSNR SIDD: 36.9217	] ----  [best_Ep_SIDD 100 best_it_SIDD 81 Best_PSNR_SIDD 36.9593] 
Epoch: 100	Time: 157.9471	Loss: 1.6005	LearningRate 0.000050
[Ep 101 it 40	 PSNR SIDD: 36.9975	] ----  [best_Ep_SIDD 101 best_it_SIDD 40 Best_PSNR_SIDD 36.9975] 
[Ep 101 it 81	 PSNR SIDD: 36.9978	] ----  [best_Ep_SIDD 101 best_it_SIDD 81 Best_PSNR_SIDD 36.9978] 
[Ep 101 it 122	 PSNR SIDD: 36.9419	] ----  [best_Ep_SIDD 101 best_it_SIDD 81 Best_PSNR_SIDD 36.9978] 
[Ep 101 it 163	 PSNR SIDD: 36.9267	] ----  [best_Ep_SIDD 101 best_it_SIDD 81 Best_PSNR_SIDD 36.9978] 
Epoch: 101	Time: 162.8718	Loss: 1.5963	LearningRate 0.000050
[Ep 102 it 40	 PSNR SIDD: 36.9267	] ----  [best_Ep_SIDD 101 best_it_SIDD 81 Best_PSNR_SIDD 36.9978] 
[Ep 102 it 81	 PSNR SIDD: 36.9630	] ----  [best_Ep_SIDD 101 best_it_SIDD 81 Best_PSNR_SIDD 36.9978] 
[Ep 102 it 122	 PSNR SIDD: 36.9840	] ----  [best_Ep_SIDD 101 best_it_SIDD 81 Best_PSNR_SIDD 36.9978] 
[Ep 102 it 163	 PSNR SIDD: 37.0055	] ----  [best_Ep_SIDD 102 best_it_SIDD 163 Best_PSNR_SIDD 37.0055] 
Epoch: 102	Time: 151.6061	Loss: 1.5781	LearningRate 0.000050
[Ep 103 it 40	 PSNR SIDD: 36.9983	] ----  [best_Ep_SIDD 102 best_it_SIDD 163 Best_PSNR_SIDD 37.0055] 
[Ep 103 it 81	 PSNR SIDD: 36.9814	] ----  [best_Ep_SIDD 102 best_it_SIDD 163 Best_PSNR_SIDD 37.0055] 
[Ep 103 it 122	 PSNR SIDD: 36.8774	] ----  [best_Ep_SIDD 102 best_it_SIDD 163 Best_PSNR_SIDD 37.0055] 
[Ep 103 it 163	 PSNR SIDD: 37.0472	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
Epoch: 103	Time: 152.0201	Loss: 1.5827	LearningRate 0.000050
[Ep 104 it 40	 PSNR SIDD: 36.9435	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 104 it 81	 PSNR SIDD: 36.9967	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 104 it 122	 PSNR SIDD: 36.9677	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 104 it 163	 PSNR SIDD: 36.9511	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
Epoch: 104	Time: 145.3740	Loss: 1.5919	LearningRate 0.000050
[Ep 105 it 40	 PSNR SIDD: 36.9250	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 105 it 81	 PSNR SIDD: 37.0149	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 105 it 122	 PSNR SIDD: 36.9845	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 105 it 163	 PSNR SIDD: 37.0209	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
Epoch: 105	Time: 145.4402	Loss: 1.5654	LearningRate 0.000050
[Ep 106 it 40	 PSNR SIDD: 36.9643	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 106 it 81	 PSNR SIDD: 37.0405	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 106 it 122	 PSNR SIDD: 36.9295	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 106 it 163	 PSNR SIDD: 36.9775	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
Epoch: 106	Time: 145.3805	Loss: 1.5891	LearningRate 0.000050
[Ep 107 it 40	 PSNR SIDD: 37.0292	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 107 it 81	 PSNR SIDD: 37.0043	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 107 it 122	 PSNR SIDD: 37.0097	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 107 it 163	 PSNR SIDD: 37.0253	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
Epoch: 107	Time: 145.5799	Loss: 1.5797	LearningRate 0.000050
[Ep 108 it 40	 PSNR SIDD: 36.9704	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 108 it 81	 PSNR SIDD: 36.9614	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 108 it 122	 PSNR SIDD: 36.9868	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 108 it 163	 PSNR SIDD: 37.0174	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
Epoch: 108	Time: 145.6531	Loss: 1.5744	LearningRate 0.000050
[Ep 109 it 40	 PSNR SIDD: 36.9638	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 109 it 81	 PSNR SIDD: 36.9924	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 109 it 122	 PSNR SIDD: 36.9315	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
[Ep 109 it 163	 PSNR SIDD: 37.0304	] ----  [best_Ep_SIDD 103 best_it_SIDD 163 Best_PSNR_SIDD 37.0472] 
Epoch: 109	Time: 145.3148	Loss: 1.5617	LearningRate 0.000050
[Ep 110 it 40	 PSNR SIDD: 37.0553	] ----  [best_Ep_SIDD 110 best_it_SIDD 40 Best_PSNR_SIDD 37.0553] 
[Ep 110 it 81	 PSNR SIDD: 37.0616	] ----  [best_Ep_SIDD 110 best_it_SIDD 81 Best_PSNR_SIDD 37.0616] 
[Ep 110 it 122	 PSNR SIDD: 37.0988	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 110 it 163	 PSNR SIDD: 37.0259	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
Epoch: 110	Time: 163.6847	Loss: 1.5656	LearningRate 0.000050
[Ep 111 it 40	 PSNR SIDD: 36.9956	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 111 it 81	 PSNR SIDD: 37.0029	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 111 it 122	 PSNR SIDD: 37.0458	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 111 it 163	 PSNR SIDD: 37.0263	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
Epoch: 111	Time: 145.7521	Loss: 1.5619	LearningRate 0.000050
[Ep 112 it 40	 PSNR SIDD: 36.9867	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 112 it 81	 PSNR SIDD: 37.0717	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 112 it 122	 PSNR SIDD: 37.0567	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 112 it 163	 PSNR SIDD: 37.0513	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
Epoch: 112	Time: 145.5423	Loss: 1.5724	LearningRate 0.000050
[Ep 113 it 40	 PSNR SIDD: 37.0651	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 113 it 81	 PSNR SIDD: 37.0515	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 113 it 122	 PSNR SIDD: 37.0520	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 113 it 163	 PSNR SIDD: 37.0352	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
Epoch: 113	Time: 145.4874	Loss: 1.5628	LearningRate 0.000050
[Ep 114 it 40	 PSNR SIDD: 37.0361	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 114 it 81	 PSNR SIDD: 37.0400	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 114 it 122	 PSNR SIDD: 37.0329	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 114 it 163	 PSNR SIDD: 37.0047	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
Epoch: 114	Time: 145.4476	Loss: 1.5709	LearningRate 0.000050
[Ep 115 it 40	 PSNR SIDD: 37.0600	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 115 it 81	 PSNR SIDD: 37.0311	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 115 it 122	 PSNR SIDD: 37.0187	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 115 it 163	 PSNR SIDD: 37.0972	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
Epoch: 115	Time: 145.5562	Loss: 1.5618	LearningRate 0.000050
[Ep 116 it 40	 PSNR SIDD: 36.9899	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 116 it 81	 PSNR SIDD: 37.0254	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 116 it 122	 PSNR SIDD: 37.0161	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 116 it 163	 PSNR SIDD: 37.0383	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
Epoch: 116	Time: 145.4941	Loss: 1.5722	LearningRate 0.000050
[Ep 117 it 40	 PSNR SIDD: 37.0910	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 117 it 81	 PSNR SIDD: 37.0245	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 117 it 122	 PSNR SIDD: 37.0758	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 117 it 163	 PSNR SIDD: 37.0102	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
Epoch: 117	Time: 145.3103	Loss: 1.5594	LearningRate 0.000050
[Ep 118 it 40	 PSNR SIDD: 37.0446	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 118 it 81	 PSNR SIDD: 37.0473	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 118 it 122	 PSNR SIDD: 36.9436	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 118 it 163	 PSNR SIDD: 37.0020	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
Epoch: 118	Time: 145.9219	Loss: 1.5723	LearningRate 0.000050
[Ep 119 it 40	 PSNR SIDD: 36.9920	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 119 it 81	 PSNR SIDD: 37.0189	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 119 it 122	 PSNR SIDD: 36.9508	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 119 it 163	 PSNR SIDD: 37.0545	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
Epoch: 119	Time: 145.4881	Loss: 1.5690	LearningRate 0.000050
[Ep 120 it 40	 PSNR SIDD: 37.0007	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 120 it 81	 PSNR SIDD: 37.0780	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 120 it 122	 PSNR SIDD: 37.0508	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 120 it 163	 PSNR SIDD: 37.0666	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
Epoch: 120	Time: 145.3425	Loss: 1.5571	LearningRate 0.000050
[Ep 121 it 40	 PSNR SIDD: 37.0934	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 121 it 81	 PSNR SIDD: 37.0230	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 121 it 122	 PSNR SIDD: 37.0754	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 121 it 163	 PSNR SIDD: 37.0577	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
Epoch: 121	Time: 145.4255	Loss: 1.5475	LearningRate 0.000050
[Ep 122 it 40	 PSNR SIDD: 37.0902	] ----  [best_Ep_SIDD 110 best_it_SIDD 122 Best_PSNR_SIDD 37.0988] 
[Ep 122 it 81	 PSNR SIDD: 37.1111	] ----  [best_Ep_SIDD 122 best_it_SIDD 81 Best_PSNR_SIDD 37.1111] 
[Ep 122 it 122	 PSNR SIDD: 37.0770	] ----  [best_Ep_SIDD 122 best_it_SIDD 81 Best_PSNR_SIDD 37.1111] 
[Ep 122 it 163	 PSNR SIDD: 37.0028	] ----  [best_Ep_SIDD 122 best_it_SIDD 81 Best_PSNR_SIDD 37.1111] 
Epoch: 122	Time: 151.4768	Loss: 1.5626	LearningRate 0.000050
[Ep 123 it 40	 PSNR SIDD: 37.0425	] ----  [best_Ep_SIDD 122 best_it_SIDD 81 Best_PSNR_SIDD 37.1111] 
[Ep 123 it 81	 PSNR SIDD: 37.1108	] ----  [best_Ep_SIDD 122 best_it_SIDD 81 Best_PSNR_SIDD 37.1111] 
[Ep 123 it 122	 PSNR SIDD: 37.1479	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 123 it 163	 PSNR SIDD: 37.0640	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
Epoch: 123	Time: 151.5149	Loss: 1.5624	LearningRate 0.000050
[Ep 124 it 40	 PSNR SIDD: 37.0657	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 124 it 81	 PSNR SIDD: 37.0803	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 124 it 122	 PSNR SIDD: 37.0604	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 124 it 163	 PSNR SIDD: 37.0823	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
Epoch: 124	Time: 145.5762	Loss: 1.5711	LearningRate 0.000050
[Ep 125 it 40	 PSNR SIDD: 37.0950	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 125 it 81	 PSNR SIDD: 37.1085	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 125 it 122	 PSNR SIDD: 37.1156	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 125 it 163	 PSNR SIDD: 37.1259	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
Epoch: 125	Time: 145.4196	Loss: 1.5694	LearningRate 0.000050
[Ep 126 it 40	 PSNR SIDD: 37.0812	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 126 it 81	 PSNR SIDD: 37.1079	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 126 it 122	 PSNR SIDD: 37.1071	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 126 it 163	 PSNR SIDD: 37.0995	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
Epoch: 126	Time: 145.3223	Loss: 1.5495	LearningRate 0.000050
[Ep 127 it 40	 PSNR SIDD: 37.1219	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 127 it 81	 PSNR SIDD: 37.0651	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 127 it 122	 PSNR SIDD: 37.0312	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 127 it 163	 PSNR SIDD: 37.0850	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
Epoch: 127	Time: 145.3770	Loss: 1.5481	LearningRate 0.000050
[Ep 128 it 40	 PSNR SIDD: 37.0547	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 128 it 81	 PSNR SIDD: 37.1208	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 128 it 122	 PSNR SIDD: 37.1422	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 128 it 163	 PSNR SIDD: 37.1253	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
Epoch: 128	Time: 145.2222	Loss: 1.5575	LearningRate 0.000050
[Ep 129 it 40	 PSNR SIDD: 37.1211	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 129 it 81	 PSNR SIDD: 37.0866	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 129 it 122	 PSNR SIDD: 37.0148	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 129 it 163	 PSNR SIDD: 37.0832	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
Epoch: 129	Time: 145.3886	Loss: 1.5564	LearningRate 0.000050
[Ep 130 it 40	 PSNR SIDD: 37.1153	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 130 it 81	 PSNR SIDD: 37.1267	] ----  [best_Ep_SIDD 123 best_it_SIDD 122 Best_PSNR_SIDD 37.1479] 
[Ep 130 it 122	 PSNR SIDD: 37.1647	] ----  [best_Ep_SIDD 130 best_it_SIDD 122 Best_PSNR_SIDD 37.1647] 
[Ep 130 it 163	 PSNR SIDD: 37.0961	] ----  [best_Ep_SIDD 130 best_it_SIDD 122 Best_PSNR_SIDD 37.1647] 
Epoch: 130	Time: 151.5461	Loss: 1.5471	LearningRate 0.000050
[Ep 131 it 40	 PSNR SIDD: 37.0854	] ----  [best_Ep_SIDD 130 best_it_SIDD 122 Best_PSNR_SIDD 37.1647] 
[Ep 131 it 81	 PSNR SIDD: 37.1509	] ----  [best_Ep_SIDD 130 best_it_SIDD 122 Best_PSNR_SIDD 37.1647] 
[Ep 131 it 122	 PSNR SIDD: 37.1645	] ----  [best_Ep_SIDD 130 best_it_SIDD 122 Best_PSNR_SIDD 37.1647] 
[Ep 131 it 163	 PSNR SIDD: 37.1058	] ----  [best_Ep_SIDD 130 best_it_SIDD 122 Best_PSNR_SIDD 37.1647] 
Epoch: 131	Time: 145.3604	Loss: 1.5628	LearningRate 0.000050
[Ep 132 it 40	 PSNR SIDD: 37.1594	] ----  [best_Ep_SIDD 130 best_it_SIDD 122 Best_PSNR_SIDD 37.1647] 
[Ep 132 it 81	 PSNR SIDD: 37.1527	] ----  [best_Ep_SIDD 130 best_it_SIDD 122 Best_PSNR_SIDD 37.1647] 
[Ep 132 it 122	 PSNR SIDD: 37.1692	] ----  [best_Ep_SIDD 132 best_it_SIDD 122 Best_PSNR_SIDD 37.1692] 
[Ep 132 it 163	 PSNR SIDD: 37.1592	] ----  [best_Ep_SIDD 132 best_it_SIDD 122 Best_PSNR_SIDD 37.1692] 
Epoch: 132	Time: 151.4561	Loss: 1.5683	LearningRate 0.000050
[Ep 133 it 40	 PSNR SIDD: 37.1563	] ----  [best_Ep_SIDD 132 best_it_SIDD 122 Best_PSNR_SIDD 37.1692] 
[Ep 133 it 81	 PSNR SIDD: 37.1721	] ----  [best_Ep_SIDD 133 best_it_SIDD 81 Best_PSNR_SIDD 37.1721] 
[Ep 133 it 122	 PSNR SIDD: 37.1585	] ----  [best_Ep_SIDD 133 best_it_SIDD 81 Best_PSNR_SIDD 37.1721] 
[Ep 133 it 163	 PSNR SIDD: 37.1687	] ----  [best_Ep_SIDD 133 best_it_SIDD 81 Best_PSNR_SIDD 37.1721] 
Epoch: 133	Time: 151.6969	Loss: 1.5615	LearningRate 0.000050
[Ep 134 it 40	 PSNR SIDD: 37.1366	] ----  [best_Ep_SIDD 133 best_it_SIDD 81 Best_PSNR_SIDD 37.1721] 
[Ep 134 it 81	 PSNR SIDD: 37.0947	] ----  [best_Ep_SIDD 133 best_it_SIDD 81 Best_PSNR_SIDD 37.1721] 
[Ep 134 it 122	 PSNR SIDD: 37.1803	] ----  [best_Ep_SIDD 134 best_it_SIDD 122 Best_PSNR_SIDD 37.1803] 
[Ep 134 it 163	 PSNR SIDD: 37.1527	] ----  [best_Ep_SIDD 134 best_it_SIDD 122 Best_PSNR_SIDD 37.1803] 
Epoch: 134	Time: 152.4623	Loss: 1.5426	LearningRate 0.000050
[Ep 135 it 40	 PSNR SIDD: 37.1534	] ----  [best_Ep_SIDD 134 best_it_SIDD 122 Best_PSNR_SIDD 37.1803] 
[Ep 135 it 81	 PSNR SIDD: 37.1230	] ----  [best_Ep_SIDD 134 best_it_SIDD 122 Best_PSNR_SIDD 37.1803] 
[Ep 135 it 122	 PSNR SIDD: 36.9888	] ----  [best_Ep_SIDD 134 best_it_SIDD 122 Best_PSNR_SIDD 37.1803] 
[Ep 135 it 163	 PSNR SIDD: 37.1253	] ----  [best_Ep_SIDD 134 best_it_SIDD 122 Best_PSNR_SIDD 37.1803] 
Epoch: 135	Time: 145.4924	Loss: 1.5461	LearningRate 0.000050
[Ep 136 it 40	 PSNR SIDD: 37.1368	] ----  [best_Ep_SIDD 134 best_it_SIDD 122 Best_PSNR_SIDD 37.1803] 
[Ep 136 it 81	 PSNR SIDD: 37.1729	] ----  [best_Ep_SIDD 134 best_it_SIDD 122 Best_PSNR_SIDD 37.1803] 
[Ep 136 it 122	 PSNR SIDD: 37.1800	] ----  [best_Ep_SIDD 134 best_it_SIDD 122 Best_PSNR_SIDD 37.1803] 
[Ep 136 it 163	 PSNR SIDD: 37.1398	] ----  [best_Ep_SIDD 134 best_it_SIDD 122 Best_PSNR_SIDD 37.1803] 
Epoch: 136	Time: 145.7214	Loss: 1.5405	LearningRate 0.000050
[Ep 137 it 40	 PSNR SIDD: 37.2159	] ----  [best_Ep_SIDD 137 best_it_SIDD 40 Best_PSNR_SIDD 37.2159] 
[Ep 137 it 81	 PSNR SIDD: 37.2153	] ----  [best_Ep_SIDD 137 best_it_SIDD 40 Best_PSNR_SIDD 37.2159] 
[Ep 137 it 122	 PSNR SIDD: 37.2386	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 137 it 163	 PSNR SIDD: 37.1951	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
Epoch: 137	Time: 157.7237	Loss: 1.5525	LearningRate 0.000050
[Ep 138 it 40	 PSNR SIDD: 37.2136	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 138 it 81	 PSNR SIDD: 37.1377	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 138 it 122	 PSNR SIDD: 37.2091	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 138 it 163	 PSNR SIDD: 37.1661	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
Epoch: 138	Time: 145.6363	Loss: 1.5503	LearningRate 0.000050
[Ep 139 it 40	 PSNR SIDD: 37.1505	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 139 it 81	 PSNR SIDD: 37.1662	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 139 it 122	 PSNR SIDD: 37.1985	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 139 it 163	 PSNR SIDD: 37.0780	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
Epoch: 139	Time: 145.4108	Loss: 1.5507	LearningRate 0.000050
[Ep 140 it 40	 PSNR SIDD: 37.1613	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 140 it 81	 PSNR SIDD: 37.2121	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 140 it 122	 PSNR SIDD: 37.1906	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 140 it 163	 PSNR SIDD: 37.1471	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
Epoch: 140	Time: 145.4481	Loss: 1.5392	LearningRate 0.000050
[Ep 141 it 40	 PSNR SIDD: 37.1795	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 141 it 81	 PSNR SIDD: 37.2116	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 141 it 122	 PSNR SIDD: 37.1604	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 141 it 163	 PSNR SIDD: 37.2259	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
Epoch: 141	Time: 145.5091	Loss: 1.5444	LearningRate 0.000050
[Ep 142 it 40	 PSNR SIDD: 37.1677	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 142 it 81	 PSNR SIDD: 37.0935	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 142 it 122	 PSNR SIDD: 37.1708	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 142 it 163	 PSNR SIDD: 37.1461	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
Epoch: 142	Time: 145.5939	Loss: 1.5552	LearningRate 0.000050
[Ep 143 it 40	 PSNR SIDD: 37.1953	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 143 it 81	 PSNR SIDD: 37.1744	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 143 it 122	 PSNR SIDD: 37.1016	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 143 it 163	 PSNR SIDD: 37.1692	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
Epoch: 143	Time: 145.5103	Loss: 1.5549	LearningRate 0.000050
[Ep 144 it 40	 PSNR SIDD: 37.1810	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 144 it 81	 PSNR SIDD: 37.1290	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 144 it 122	 PSNR SIDD: 37.1772	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 144 it 163	 PSNR SIDD: 37.1144	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
Epoch: 144	Time: 145.3815	Loss: 1.5480	LearningRate 0.000050
[Ep 145 it 40	 PSNR SIDD: 37.2150	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 145 it 81	 PSNR SIDD: 37.1999	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 145 it 122	 PSNR SIDD: 37.1956	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 145 it 163	 PSNR SIDD: 37.2192	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
Epoch: 145	Time: 145.3494	Loss: 1.5505	LearningRate 0.000050
[Ep 146 it 40	 PSNR SIDD: 37.1741	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 146 it 81	 PSNR SIDD: 37.1881	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 146 it 122	 PSNR SIDD: 37.1626	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 146 it 163	 PSNR SIDD: 37.1899	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
Epoch: 146	Time: 145.4233	Loss: 1.5442	LearningRate 0.000050
[Ep 147 it 40	 PSNR SIDD: 37.1253	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 147 it 81	 PSNR SIDD: 37.1872	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 147 it 122	 PSNR SIDD: 37.2282	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 147 it 163	 PSNR SIDD: 37.1537	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
Epoch: 147	Time: 145.2440	Loss: 1.5467	LearningRate 0.000050
[Ep 148 it 40	 PSNR SIDD: 37.1731	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 148 it 81	 PSNR SIDD: 37.1833	] ----  [best_Ep_SIDD 137 best_it_SIDD 122 Best_PSNR_SIDD 37.2386] 
[Ep 148 it 122	 PSNR SIDD: 37.2629	] ----  [best_Ep_SIDD 148 best_it_SIDD 122 Best_PSNR_SIDD 37.2629] 
[Ep 148 it 163	 PSNR SIDD: 37.2472	] ----  [best_Ep_SIDD 148 best_it_SIDD 122 Best_PSNR_SIDD 37.2629] 
Epoch: 148	Time: 152.5329	Loss: 1.5316	LearningRate 0.000050
[Ep 149 it 40	 PSNR SIDD: 37.0639	] ----  [best_Ep_SIDD 148 best_it_SIDD 122 Best_PSNR_SIDD 37.2629] 
[Ep 149 it 81	 PSNR SIDD: 37.2086	] ----  [best_Ep_SIDD 148 best_it_SIDD 122 Best_PSNR_SIDD 37.2629] 
[Ep 149 it 122	 PSNR SIDD: 37.1989	] ----  [best_Ep_SIDD 148 best_it_SIDD 122 Best_PSNR_SIDD 37.2629] 
[Ep 149 it 163	 PSNR SIDD: 37.1638	] ----  [best_Ep_SIDD 148 best_it_SIDD 122 Best_PSNR_SIDD 37.2629] 
Epoch: 149	Time: 145.5950	Loss: 1.5397	LearningRate 0.000013
[Ep 150 it 40	 PSNR SIDD: 37.2169	] ----  [best_Ep_SIDD 148 best_it_SIDD 122 Best_PSNR_SIDD 37.2629] 
[Ep 150 it 81	 PSNR SIDD: 37.2334	] ----  [best_Ep_SIDD 148 best_it_SIDD 122 Best_PSNR_SIDD 37.2629] 
[Ep 150 it 122	 PSNR SIDD: 37.2621	] ----  [best_Ep_SIDD 148 best_it_SIDD 122 Best_PSNR_SIDD 37.2629] 
[Ep 150 it 163	 PSNR SIDD: 37.2568	] ----  [best_Ep_SIDD 148 best_it_SIDD 122 Best_PSNR_SIDD 37.2629] 
Epoch: 150	Time: 145.3643	Loss: 1.5447	LearningRate 0.000025
[Ep 151 it 40	 PSNR SIDD: 37.2551	] ----  [best_Ep_SIDD 148 best_it_SIDD 122 Best_PSNR_SIDD 37.2629] 
[Ep 151 it 81	 PSNR SIDD: 37.2532	] ----  [best_Ep_SIDD 148 best_it_SIDD 122 Best_PSNR_SIDD 37.2629] 
[Ep 151 it 122	 PSNR SIDD: 37.2859	] ----  [best_Ep_SIDD 151 best_it_SIDD 122 Best_PSNR_SIDD 37.2859] 
[Ep 151 it 163	 PSNR SIDD: 37.2778	] ----  [best_Ep_SIDD 151 best_it_SIDD 122 Best_PSNR_SIDD 37.2859] 
Epoch: 151	Time: 152.2348	Loss: 1.5361	LearningRate 0.000025
[Ep 152 it 40	 PSNR SIDD: 37.2210	] ----  [best_Ep_SIDD 151 best_it_SIDD 122 Best_PSNR_SIDD 37.2859] 
[Ep 152 it 81	 PSNR SIDD: 37.2684	] ----  [best_Ep_SIDD 151 best_it_SIDD 122 Best_PSNR_SIDD 37.2859] 
[Ep 152 it 122	 PSNR SIDD: 37.2951	] ----  [best_Ep_SIDD 152 best_it_SIDD 122 Best_PSNR_SIDD 37.2951] 
[Ep 152 it 163	 PSNR SIDD: 37.2847	] ----  [best_Ep_SIDD 152 best_it_SIDD 122 Best_PSNR_SIDD 37.2951] 
Epoch: 152	Time: 152.0218	Loss: 1.5336	LearningRate 0.000025
[Ep 153 it 40	 PSNR SIDD: 37.2869	] ----  [best_Ep_SIDD 152 best_it_SIDD 122 Best_PSNR_SIDD 37.2951] 
[Ep 153 it 81	 PSNR SIDD: 37.2703	] ----  [best_Ep_SIDD 152 best_it_SIDD 122 Best_PSNR_SIDD 37.2951] 
[Ep 153 it 122	 PSNR SIDD: 37.2618	] ----  [best_Ep_SIDD 152 best_it_SIDD 122 Best_PSNR_SIDD 37.2951] 
[Ep 153 it 163	 PSNR SIDD: 37.2572	] ----  [best_Ep_SIDD 152 best_it_SIDD 122 Best_PSNR_SIDD 37.2951] 
Epoch: 153	Time: 145.5255	Loss: 1.5226	LearningRate 0.000025
[Ep 154 it 40	 PSNR SIDD: 37.2777	] ----  [best_Ep_SIDD 152 best_it_SIDD 122 Best_PSNR_SIDD 37.2951] 
[Ep 154 it 81	 PSNR SIDD: 37.2934	] ----  [best_Ep_SIDD 152 best_it_SIDD 122 Best_PSNR_SIDD 37.2951] 
[Ep 154 it 122	 PSNR SIDD: 37.2893	] ----  [best_Ep_SIDD 152 best_it_SIDD 122 Best_PSNR_SIDD 37.2951] 
[Ep 154 it 163	 PSNR SIDD: 37.2568	] ----  [best_Ep_SIDD 152 best_it_SIDD 122 Best_PSNR_SIDD 37.2951] 
Epoch: 154	Time: 145.5793	Loss: 1.5262	LearningRate 0.000025
[Ep 155 it 40	 PSNR SIDD: 37.2782	] ----  [best_Ep_SIDD 152 best_it_SIDD 122 Best_PSNR_SIDD 37.2951] 
[Ep 155 it 81	 PSNR SIDD: 37.3172	] ----  [best_Ep_SIDD 155 best_it_SIDD 81 Best_PSNR_SIDD 37.3172] 
[Ep 155 it 122	 PSNR SIDD: 37.2552	] ----  [best_Ep_SIDD 155 best_it_SIDD 81 Best_PSNR_SIDD 37.3172] 
[Ep 155 it 163	 PSNR SIDD: 37.3058	] ----  [best_Ep_SIDD 155 best_it_SIDD 81 Best_PSNR_SIDD 37.3172] 
Epoch: 155	Time: 151.7868	Loss: 1.5335	LearningRate 0.000025
[Ep 156 it 40	 PSNR SIDD: 37.3150	] ----  [best_Ep_SIDD 155 best_it_SIDD 81 Best_PSNR_SIDD 37.3172] 
[Ep 156 it 81	 PSNR SIDD: 37.3035	] ----  [best_Ep_SIDD 155 best_it_SIDD 81 Best_PSNR_SIDD 37.3172] 
[Ep 156 it 122	 PSNR SIDD: 37.2653	] ----  [best_Ep_SIDD 155 best_it_SIDD 81 Best_PSNR_SIDD 37.3172] 
[Ep 156 it 163	 PSNR SIDD: 37.3002	] ----  [best_Ep_SIDD 155 best_it_SIDD 81 Best_PSNR_SIDD 37.3172] 
Epoch: 156	Time: 145.6282	Loss: 1.5250	LearningRate 0.000025
[Ep 157 it 40	 PSNR SIDD: 37.2758	] ----  [best_Ep_SIDD 155 best_it_SIDD 81 Best_PSNR_SIDD 37.3172] 
[Ep 157 it 81	 PSNR SIDD: 37.3461	] ----  [best_Ep_SIDD 157 best_it_SIDD 81 Best_PSNR_SIDD 37.3461] 
[Ep 157 it 122	 PSNR SIDD: 37.3044	] ----  [best_Ep_SIDD 157 best_it_SIDD 81 Best_PSNR_SIDD 37.3461] 
[Ep 157 it 163	 PSNR SIDD: 37.2646	] ----  [best_Ep_SIDD 157 best_it_SIDD 81 Best_PSNR_SIDD 37.3461] 
Epoch: 157	Time: 151.7425	Loss: 1.5290	LearningRate 0.000025
[Ep 158 it 40	 PSNR SIDD: 37.3230	] ----  [best_Ep_SIDD 157 best_it_SIDD 81 Best_PSNR_SIDD 37.3461] 
[Ep 158 it 81	 PSNR SIDD: 37.2538	] ----  [best_Ep_SIDD 157 best_it_SIDD 81 Best_PSNR_SIDD 37.3461] 
[Ep 158 it 122	 PSNR SIDD: 37.3458	] ----  [best_Ep_SIDD 157 best_it_SIDD 81 Best_PSNR_SIDD 37.3461] 
[Ep 158 it 163	 PSNR SIDD: 37.2554	] ----  [best_Ep_SIDD 157 best_it_SIDD 81 Best_PSNR_SIDD 37.3461] 
Epoch: 158	Time: 145.8104	Loss: 1.5259	LearningRate 0.000025
[Ep 159 it 40	 PSNR SIDD: 37.2837	] ----  [best_Ep_SIDD 157 best_it_SIDD 81 Best_PSNR_SIDD 37.3461] 
[Ep 159 it 81	 PSNR SIDD: 37.2914	] ----  [best_Ep_SIDD 157 best_it_SIDD 81 Best_PSNR_SIDD 37.3461] 
[Ep 159 it 122	 PSNR SIDD: 37.3154	] ----  [best_Ep_SIDD 157 best_it_SIDD 81 Best_PSNR_SIDD 37.3461] 
[Ep 159 it 163	 PSNR SIDD: 37.3443	] ----  [best_Ep_SIDD 157 best_it_SIDD 81 Best_PSNR_SIDD 37.3461] 
Epoch: 159	Time: 145.5594	Loss: 1.5287	LearningRate 0.000025
[Ep 160 it 40	 PSNR SIDD: 37.3491	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 160 it 81	 PSNR SIDD: 37.3166	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 160 it 122	 PSNR SIDD: 37.3052	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 160 it 163	 PSNR SIDD: 37.3118	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
Epoch: 160	Time: 151.9595	Loss: 1.5097	LearningRate 0.000025
[Ep 161 it 40	 PSNR SIDD: 37.3102	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 161 it 81	 PSNR SIDD: 37.3153	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 161 it 122	 PSNR SIDD: 37.2809	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 161 it 163	 PSNR SIDD: 37.3124	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
Epoch: 161	Time: 145.8070	Loss: 1.5297	LearningRate 0.000025
[Ep 162 it 40	 PSNR SIDD: 37.3203	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 162 it 81	 PSNR SIDD: 37.3299	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 162 it 122	 PSNR SIDD: 37.3245	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 162 it 163	 PSNR SIDD: 37.2792	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
Epoch: 162	Time: 145.5349	Loss: 1.5158	LearningRate 0.000025
[Ep 163 it 40	 PSNR SIDD: 37.3368	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 163 it 81	 PSNR SIDD: 37.3065	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 163 it 122	 PSNR SIDD: 37.3305	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 163 it 163	 PSNR SIDD: 37.2472	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
Epoch: 163	Time: 145.6298	Loss: 1.5325	LearningRate 0.000025
[Ep 164 it 40	 PSNR SIDD: 37.2865	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 164 it 81	 PSNR SIDD: 37.3005	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 164 it 122	 PSNR SIDD: 37.2987	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 164 it 163	 PSNR SIDD: 37.3152	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
Epoch: 164	Time: 145.5393	Loss: 1.5292	LearningRate 0.000025
[Ep 165 it 40	 PSNR SIDD: 37.3236	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 165 it 81	 PSNR SIDD: 37.3322	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 165 it 122	 PSNR SIDD: 37.3422	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 165 it 163	 PSNR SIDD: 37.2888	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
Epoch: 165	Time: 145.3830	Loss: 1.5192	LearningRate 0.000025
[Ep 166 it 40	 PSNR SIDD: 37.3025	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 166 it 81	 PSNR SIDD: 37.3140	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 166 it 122	 PSNR SIDD: 37.2779	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 166 it 163	 PSNR SIDD: 37.3470	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
Epoch: 166	Time: 145.5352	Loss: 1.5178	LearningRate 0.000025
[Ep 167 it 40	 PSNR SIDD: 37.3380	] ----  [best_Ep_SIDD 160 best_it_SIDD 40 Best_PSNR_SIDD 37.3491] 
[Ep 167 it 81	 PSNR SIDD: 37.3692	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
[Ep 167 it 122	 PSNR SIDD: 37.2980	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
[Ep 167 it 163	 PSNR SIDD: 37.3582	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
Epoch: 167	Time: 151.9188	Loss: 1.5212	LearningRate 0.000025
[Ep 168 it 40	 PSNR SIDD: 37.3271	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
[Ep 168 it 81	 PSNR SIDD: 37.3422	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
[Ep 168 it 122	 PSNR SIDD: 37.2705	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
[Ep 168 it 163	 PSNR SIDD: 37.3549	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
Epoch: 168	Time: 145.5537	Loss: 1.5385	LearningRate 0.000025
[Ep 169 it 40	 PSNR SIDD: 37.3293	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
[Ep 169 it 81	 PSNR SIDD: 37.3014	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
[Ep 169 it 122	 PSNR SIDD: 37.3194	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
[Ep 169 it 163	 PSNR SIDD: 37.2786	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
Epoch: 169	Time: 146.2510	Loss: 1.5121	LearningRate 0.000025
[Ep 170 it 40	 PSNR SIDD: 37.3377	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
[Ep 170 it 81	 PSNR SIDD: 37.3333	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
[Ep 170 it 122	 PSNR SIDD: 37.3229	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
[Ep 170 it 163	 PSNR SIDD: 37.3408	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
Epoch: 170	Time: 145.5523	Loss: 1.5282	LearningRate 0.000025
[Ep 171 it 40	 PSNR SIDD: 37.3437	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
[Ep 171 it 81	 PSNR SIDD: 37.3361	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
[Ep 171 it 122	 PSNR SIDD: 37.3191	] ----  [best_Ep_SIDD 167 best_it_SIDD 81 Best_PSNR_SIDD 37.3692] 
[Ep 171 it 163	 PSNR SIDD: 37.3698	] ----  [best_Ep_SIDD 171 best_it_SIDD 163 Best_PSNR_SIDD 37.3698] 
Epoch: 171	Time: 152.0586	Loss: 1.5307	LearningRate 0.000025
[Ep 172 it 40	 PSNR SIDD: 37.3719	] ----  [best_Ep_SIDD 172 best_it_SIDD 40 Best_PSNR_SIDD 37.3719] 
[Ep 172 it 81	 PSNR SIDD: 37.3657	] ----  [best_Ep_SIDD 172 best_it_SIDD 40 Best_PSNR_SIDD 37.3719] 
[Ep 172 it 122	 PSNR SIDD: 37.3322	] ----  [best_Ep_SIDD 172 best_it_SIDD 40 Best_PSNR_SIDD 37.3719] 
[Ep 172 it 163	 PSNR SIDD: 37.3552	] ----  [best_Ep_SIDD 172 best_it_SIDD 40 Best_PSNR_SIDD 37.3719] 
Epoch: 172	Time: 152.2437	Loss: 1.5212	LearningRate 0.000025
[Ep 173 it 40	 PSNR SIDD: 37.3407	] ----  [best_Ep_SIDD 172 best_it_SIDD 40 Best_PSNR_SIDD 37.3719] 
[Ep 173 it 81	 PSNR SIDD: 37.3373	] ----  [best_Ep_SIDD 172 best_it_SIDD 40 Best_PSNR_SIDD 37.3719] 
[Ep 173 it 122	 PSNR SIDD: 37.3179	] ----  [best_Ep_SIDD 172 best_it_SIDD 40 Best_PSNR_SIDD 37.3719] 
[Ep 173 it 163	 PSNR SIDD: 37.3454	] ----  [best_Ep_SIDD 172 best_it_SIDD 40 Best_PSNR_SIDD 37.3719] 
Epoch: 173	Time: 145.6518	Loss: 1.5160	LearningRate 0.000025
[Ep 174 it 40	 PSNR SIDD: 37.3742	] ----  [best_Ep_SIDD 174 best_it_SIDD 40 Best_PSNR_SIDD 37.3742] 
[Ep 174 it 81	 PSNR SIDD: 37.3984	] ----  [best_Ep_SIDD 174 best_it_SIDD 81 Best_PSNR_SIDD 37.3984] 
[Ep 174 it 122	 PSNR SIDD: 37.3631	] ----  [best_Ep_SIDD 174 best_it_SIDD 81 Best_PSNR_SIDD 37.3984] 
[Ep 174 it 163	 PSNR SIDD: 37.3918	] ----  [best_Ep_SIDD 174 best_it_SIDD 81 Best_PSNR_SIDD 37.3984] 
Epoch: 174	Time: 158.4600	Loss: 1.5163	LearningRate 0.000025
[Ep 175 it 40	 PSNR SIDD: 37.3498	] ----  [best_Ep_SIDD 174 best_it_SIDD 81 Best_PSNR_SIDD 37.3984] 
[Ep 175 it 81	 PSNR SIDD: 37.3426	] ----  [best_Ep_SIDD 174 best_it_SIDD 81 Best_PSNR_SIDD 37.3984] 
[Ep 175 it 122	 PSNR SIDD: 37.3261	] ----  [best_Ep_SIDD 174 best_it_SIDD 81 Best_PSNR_SIDD 37.3984] 
[Ep 175 it 163	 PSNR SIDD: 37.3865	] ----  [best_Ep_SIDD 174 best_it_SIDD 81 Best_PSNR_SIDD 37.3984] 
Epoch: 175	Time: 145.6560	Loss: 1.5181	LearningRate 0.000025
[Ep 176 it 40	 PSNR SIDD: 37.3866	] ----  [best_Ep_SIDD 174 best_it_SIDD 81 Best_PSNR_SIDD 37.3984] 
[Ep 176 it 81	 PSNR SIDD: 37.4053	] ----  [best_Ep_SIDD 176 best_it_SIDD 81 Best_PSNR_SIDD 37.4053] 
[Ep 176 it 122	 PSNR SIDD: 37.2921	] ----  [best_Ep_SIDD 176 best_it_SIDD 81 Best_PSNR_SIDD 37.4053] 
[Ep 176 it 163	 PSNR SIDD: 37.3466	] ----  [best_Ep_SIDD 176 best_it_SIDD 81 Best_PSNR_SIDD 37.4053] 
Epoch: 176	Time: 152.6517	Loss: 1.5126	LearningRate 0.000025
[Ep 177 it 40	 PSNR SIDD: 37.3939	] ----  [best_Ep_SIDD 176 best_it_SIDD 81 Best_PSNR_SIDD 37.4053] 
[Ep 177 it 81	 PSNR SIDD: 37.3957	] ----  [best_Ep_SIDD 176 best_it_SIDD 81 Best_PSNR_SIDD 37.4053] 
[Ep 177 it 122	 PSNR SIDD: 37.4195	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 177 it 163	 PSNR SIDD: 37.2875	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
Epoch: 177	Time: 152.1133	Loss: 1.5227	LearningRate 0.000025
[Ep 178 it 40	 PSNR SIDD: 37.3576	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 178 it 81	 PSNR SIDD: 37.3709	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 178 it 122	 PSNR SIDD: 37.3857	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 178 it 163	 PSNR SIDD: 37.3838	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
Epoch: 178	Time: 145.9436	Loss: 1.5008	LearningRate 0.000025
[Ep 179 it 40	 PSNR SIDD: 37.3947	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 179 it 81	 PSNR SIDD: 37.3349	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 179 it 122	 PSNR SIDD: 37.3622	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 179 it 163	 PSNR SIDD: 37.3910	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
Epoch: 179	Time: 146.0159	Loss: 1.5154	LearningRate 0.000025
[Ep 180 it 40	 PSNR SIDD: 37.3844	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 180 it 81	 PSNR SIDD: 37.3311	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 180 it 122	 PSNR SIDD: 37.3704	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 180 it 163	 PSNR SIDD: 37.3672	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
Epoch: 180	Time: 145.6793	Loss: 1.5191	LearningRate 0.000025
[Ep 181 it 40	 PSNR SIDD: 37.3616	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 181 it 81	 PSNR SIDD: 37.3957	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 181 it 122	 PSNR SIDD: 37.3703	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 181 it 163	 PSNR SIDD: 37.3877	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
Epoch: 181	Time: 145.6561	Loss: 1.5295	LearningRate 0.000025
[Ep 182 it 40	 PSNR SIDD: 37.3765	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 182 it 81	 PSNR SIDD: 37.3868	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 182 it 122	 PSNR SIDD: 37.3600	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 182 it 163	 PSNR SIDD: 37.3410	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
Epoch: 182	Time: 145.6079	Loss: 1.5152	LearningRate 0.000025
[Ep 183 it 40	 PSNR SIDD: 37.3813	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 183 it 81	 PSNR SIDD: 37.3603	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 183 it 122	 PSNR SIDD: 37.3754	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 183 it 163	 PSNR SIDD: 37.3864	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
Epoch: 183	Time: 145.6031	Loss: 1.5280	LearningRate 0.000025
[Ep 184 it 40	 PSNR SIDD: 37.3382	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 184 it 81	 PSNR SIDD: 37.3542	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 184 it 122	 PSNR SIDD: 37.3903	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 184 it 163	 PSNR SIDD: 37.3962	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
Epoch: 184	Time: 145.4870	Loss: 1.4945	LearningRate 0.000025
[Ep 185 it 40	 PSNR SIDD: 37.4073	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 185 it 81	 PSNR SIDD: 37.3854	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 185 it 122	 PSNR SIDD: 37.3631	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 185 it 163	 PSNR SIDD: 37.3730	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
Epoch: 185	Time: 145.4351	Loss: 1.5116	LearningRate 0.000025
[Ep 186 it 40	 PSNR SIDD: 37.3731	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 186 it 81	 PSNR SIDD: 37.3207	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 186 it 122	 PSNR SIDD: 37.3968	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 186 it 163	 PSNR SIDD: 37.4125	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
Epoch: 186	Time: 145.4984	Loss: 1.5077	LearningRate 0.000025
[Ep 187 it 40	 PSNR SIDD: 37.3726	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 187 it 81	 PSNR SIDD: 37.3970	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 187 it 122	 PSNR SIDD: 37.4105	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 187 it 163	 PSNR SIDD: 37.3727	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
Epoch: 187	Time: 145.3644	Loss: 1.5245	LearningRate 0.000025
[Ep 188 it 40	 PSNR SIDD: 37.3645	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 188 it 81	 PSNR SIDD: 37.3804	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 188 it 122	 PSNR SIDD: 37.3682	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 188 it 163	 PSNR SIDD: 37.3582	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
Epoch: 188	Time: 145.5395	Loss: 1.5136	LearningRate 0.000025
[Ep 189 it 40	 PSNR SIDD: 37.3977	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 189 it 81	 PSNR SIDD: 37.3724	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 189 it 122	 PSNR SIDD: 37.3593	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 189 it 163	 PSNR SIDD: 37.4094	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
Epoch: 189	Time: 145.8174	Loss: 1.5075	LearningRate 0.000025
[Ep 190 it 40	 PSNR SIDD: 37.3869	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 190 it 81	 PSNR SIDD: 37.3469	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 190 it 122	 PSNR SIDD: 37.3530	] ----  [best_Ep_SIDD 177 best_it_SIDD 122 Best_PSNR_SIDD 37.4195] 
[Ep 190 it 163	 PSNR SIDD: 37.4244	] ----  [best_Ep_SIDD 190 best_it_SIDD 163 Best_PSNR_SIDD 37.4244] 
Epoch: 190	Time: 151.7364	Loss: 1.5075	LearningRate 0.000025
[Ep 191 it 40	 PSNR SIDD: 37.3796	] ----  [best_Ep_SIDD 190 best_it_SIDD 163 Best_PSNR_SIDD 37.4244] 
[Ep 191 it 81	 PSNR SIDD: 37.3805	] ----  [best_Ep_SIDD 190 best_it_SIDD 163 Best_PSNR_SIDD 37.4244] 
[Ep 191 it 122	 PSNR SIDD: 37.4030	] ----  [best_Ep_SIDD 190 best_it_SIDD 163 Best_PSNR_SIDD 37.4244] 
[Ep 191 it 163	 PSNR SIDD: 37.4009	] ----  [best_Ep_SIDD 190 best_it_SIDD 163 Best_PSNR_SIDD 37.4244] 
Epoch: 191	Time: 145.4674	Loss: 1.5058	LearningRate 0.000025
[Ep 192 it 40	 PSNR SIDD: 37.3765	] ----  [best_Ep_SIDD 190 best_it_SIDD 163 Best_PSNR_SIDD 37.4244] 
[Ep 192 it 81	 PSNR SIDD: 37.3958	] ----  [best_Ep_SIDD 190 best_it_SIDD 163 Best_PSNR_SIDD 37.4244] 
[Ep 192 it 122	 PSNR SIDD: 37.3957	] ----  [best_Ep_SIDD 190 best_it_SIDD 163 Best_PSNR_SIDD 37.4244] 
[Ep 192 it 163	 PSNR SIDD: 37.3997	] ----  [best_Ep_SIDD 190 best_it_SIDD 163 Best_PSNR_SIDD 37.4244] 
Epoch: 192	Time: 145.8267	Loss: 1.5069	LearningRate 0.000025
[Ep 193 it 40	 PSNR SIDD: 37.3991	] ----  [best_Ep_SIDD 190 best_it_SIDD 163 Best_PSNR_SIDD 37.4244] 
[Ep 193 it 81	 PSNR SIDD: 37.3778	] ----  [best_Ep_SIDD 190 best_it_SIDD 163 Best_PSNR_SIDD 37.4244] 
[Ep 193 it 122	 PSNR SIDD: 37.3562	] ----  [best_Ep_SIDD 190 best_it_SIDD 163 Best_PSNR_SIDD 37.4244] 
[Ep 193 it 163	 PSNR SIDD: 37.3661	] ----  [best_Ep_SIDD 190 best_it_SIDD 163 Best_PSNR_SIDD 37.4244] 
Epoch: 193	Time: 145.5810	Loss: 1.4932	LearningRate 0.000025
[Ep 194 it 40	 PSNR SIDD: 37.3738	] ----  [best_Ep_SIDD 190 best_it_SIDD 163 Best_PSNR_SIDD 37.4244] 
[Ep 194 it 81	 PSNR SIDD: 37.3861	] ----  [best_Ep_SIDD 190 best_it_SIDD 163 Best_PSNR_SIDD 37.4244] 
[Ep 194 it 122	 PSNR SIDD: 37.3995	] ----  [best_Ep_SIDD 190 best_it_SIDD 163 Best_PSNR_SIDD 37.4244] 
[Ep 194 it 163	 PSNR SIDD: 37.4297	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
Epoch: 194	Time: 152.0030	Loss: 1.5081	LearningRate 0.000025
[Ep 195 it 40	 PSNR SIDD: 37.4166	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
[Ep 195 it 81	 PSNR SIDD: 37.3942	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
[Ep 195 it 122	 PSNR SIDD: 37.4046	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
[Ep 195 it 163	 PSNR SIDD: 37.4173	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
Epoch: 195	Time: 145.6398	Loss: 1.5010	LearningRate 0.000025
[Ep 196 it 40	 PSNR SIDD: 37.3956	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
[Ep 196 it 81	 PSNR SIDD: 37.3512	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
[Ep 196 it 122	 PSNR SIDD: 37.3615	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
[Ep 196 it 163	 PSNR SIDD: 37.3823	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
Epoch: 196	Time: 145.5420	Loss: 1.5003	LearningRate 0.000025
[Ep 197 it 40	 PSNR SIDD: 37.3424	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
[Ep 197 it 81	 PSNR SIDD: 37.3148	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
[Ep 197 it 122	 PSNR SIDD: 37.4093	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
[Ep 197 it 163	 PSNR SIDD: 37.3968	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
Epoch: 197	Time: 145.6294	Loss: 1.5108	LearningRate 0.000025
[Ep 198 it 40	 PSNR SIDD: 37.4214	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
[Ep 198 it 81	 PSNR SIDD: 37.4247	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
[Ep 198 it 122	 PSNR SIDD: 37.4080	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
[Ep 198 it 163	 PSNR SIDD: 37.4115	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
Epoch: 198	Time: 145.5413	Loss: 1.5082	LearningRate 0.000025
[Ep 199 it 40	 PSNR SIDD: 37.4058	] ----  [best_Ep_SIDD 194 best_it_SIDD 163 Best_PSNR_SIDD 37.4297] 
[Ep 199 it 81	 PSNR SIDD: 37.4433	] ----  [best_Ep_SIDD 199 best_it_SIDD 81 Best_PSNR_SIDD 37.4433] 
[Ep 199 it 122	 PSNR SIDD: 37.4444	] ----  [best_Ep_SIDD 199 best_it_SIDD 122 Best_PSNR_SIDD 37.4444] 
[Ep 199 it 163	 PSNR SIDD: 37.4627	] ----  [best_Ep_SIDD 199 best_it_SIDD 163 Best_PSNR_SIDD 37.4627] 
Epoch: 199	Time: 164.5769	Loss: 1.5156	LearningRate 0.000006
[Ep 200 it 40	 PSNR SIDD: 37.4410	] ----  [best_Ep_SIDD 199 best_it_SIDD 163 Best_PSNR_SIDD 37.4627] 
[Ep 200 it 81	 PSNR SIDD: 37.4210	] ----  [best_Ep_SIDD 199 best_it_SIDD 163 Best_PSNR_SIDD 37.4627] 
[Ep 200 it 122	 PSNR SIDD: 37.4579	] ----  [best_Ep_SIDD 199 best_it_SIDD 163 Best_PSNR_SIDD 37.4627] 
[Ep 200 it 163	 PSNR SIDD: 37.4396	] ----  [best_Ep_SIDD 199 best_it_SIDD 163 Best_PSNR_SIDD 37.4627] 
Epoch: 200	Time: 145.8713	Loss: 1.4911	LearningRate 0.000013
[Ep 201 it 40	 PSNR SIDD: 37.4480	] ----  [best_Ep_SIDD 199 best_it_SIDD 163 Best_PSNR_SIDD 37.4627] 
[Ep 201 it 81	 PSNR SIDD: 37.4267	] ----  [best_Ep_SIDD 199 best_it_SIDD 163 Best_PSNR_SIDD 37.4627] 
[Ep 201 it 122	 PSNR SIDD: 37.4521	] ----  [best_Ep_SIDD 199 best_it_SIDD 163 Best_PSNR_SIDD 37.4627] 
[Ep 201 it 163	 PSNR SIDD: 37.4511	] ----  [best_Ep_SIDD 199 best_it_SIDD 163 Best_PSNR_SIDD 37.4627] 
Epoch: 201	Time: 145.7392	Loss: 1.5073	LearningRate 0.000013
[Ep 202 it 40	 PSNR SIDD: 37.4835	] ----  [best_Ep_SIDD 202 best_it_SIDD 40 Best_PSNR_SIDD 37.4835] 
[Ep 202 it 81	 PSNR SIDD: 37.4908	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 202 it 122	 PSNR SIDD: 37.4591	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 202 it 163	 PSNR SIDD: 37.4500	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
Epoch: 202	Time: 158.4878	Loss: 1.5062	LearningRate 0.000013
[Ep 203 it 40	 PSNR SIDD: 37.4468	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 203 it 81	 PSNR SIDD: 37.4454	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 203 it 122	 PSNR SIDD: 37.4182	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 203 it 163	 PSNR SIDD: 37.4500	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
Epoch: 203	Time: 145.7917	Loss: 1.4981	LearningRate 0.000013
[Ep 204 it 40	 PSNR SIDD: 37.4362	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 204 it 81	 PSNR SIDD: 37.4231	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 204 it 122	 PSNR SIDD: 37.4821	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 204 it 163	 PSNR SIDD: 37.4511	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
Epoch: 204	Time: 146.0866	Loss: 1.5018	LearningRate 0.000013
[Ep 205 it 40	 PSNR SIDD: 37.4511	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 205 it 81	 PSNR SIDD: 37.3985	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 205 it 122	 PSNR SIDD: 37.4599	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 205 it 163	 PSNR SIDD: 37.4658	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
Epoch: 205	Time: 145.8920	Loss: 1.4981	LearningRate 0.000013
[Ep 206 it 40	 PSNR SIDD: 37.4739	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 206 it 81	 PSNR SIDD: 37.4681	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 206 it 122	 PSNR SIDD: 37.4325	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 206 it 163	 PSNR SIDD: 37.4591	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
Epoch: 206	Time: 145.9843	Loss: 1.5037	LearningRate 0.000013
[Ep 207 it 40	 PSNR SIDD: 37.4634	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 207 it 81	 PSNR SIDD: 37.4445	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 207 it 122	 PSNR SIDD: 37.4425	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 207 it 163	 PSNR SIDD: 37.4445	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
Epoch: 207	Time: 145.9649	Loss: 1.5063	LearningRate 0.000013
[Ep 208 it 40	 PSNR SIDD: 37.4330	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 208 it 81	 PSNR SIDD: 37.4489	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 208 it 122	 PSNR SIDD: 37.4139	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 208 it 163	 PSNR SIDD: 37.4524	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
Epoch: 208	Time: 146.0640	Loss: 1.4944	LearningRate 0.000013
[Ep 209 it 40	 PSNR SIDD: 37.4448	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 209 it 81	 PSNR SIDD: 37.4410	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 209 it 122	 PSNR SIDD: 37.4555	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 209 it 163	 PSNR SIDD: 37.4600	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
Epoch: 209	Time: 145.9549	Loss: 1.4913	LearningRate 0.000013
[Ep 210 it 40	 PSNR SIDD: 37.4468	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 210 it 81	 PSNR SIDD: 37.4431	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 210 it 122	 PSNR SIDD: 37.4490	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 210 it 163	 PSNR SIDD: 37.4683	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
Epoch: 210	Time: 147.8092	Loss: 1.5036	LearningRate 0.000013
[Ep 211 it 40	 PSNR SIDD: 37.4429	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 211 it 81	 PSNR SIDD: 37.4535	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 211 it 122	 PSNR SIDD: 37.4274	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 211 it 163	 PSNR SIDD: 37.4252	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
Epoch: 211	Time: 145.8822	Loss: 1.4815	LearningRate 0.000013
[Ep 212 it 40	 PSNR SIDD: 37.4582	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 212 it 81	 PSNR SIDD: 37.4295	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 212 it 122	 PSNR SIDD: 37.4560	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 212 it 163	 PSNR SIDD: 37.4131	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
Epoch: 212	Time: 147.8819	Loss: 1.4985	LearningRate 0.000013
[Ep 213 it 40	 PSNR SIDD: 37.4277	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 213 it 81	 PSNR SIDD: 37.4590	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 213 it 122	 PSNR SIDD: 37.4693	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 213 it 163	 PSNR SIDD: 37.4507	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
Epoch: 213	Time: 147.4132	Loss: 1.5124	LearningRate 0.000013
[Ep 214 it 40	 PSNR SIDD: 37.4795	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 214 it 81	 PSNR SIDD: 37.4333	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 214 it 122	 PSNR SIDD: 37.4382	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 214 it 163	 PSNR SIDD: 37.4588	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
Epoch: 214	Time: 147.6263	Loss: 1.4964	LearningRate 0.000013
[Ep 215 it 40	 PSNR SIDD: 37.4446	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 215 it 81	 PSNR SIDD: 37.4723	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 215 it 122	 PSNR SIDD: 37.4623	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 215 it 163	 PSNR SIDD: 37.4739	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
Epoch: 215	Time: 147.6492	Loss: 1.4795	LearningRate 0.000013
[Ep 216 it 40	 PSNR SIDD: 37.4200	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 216 it 81	 PSNR SIDD: 37.4474	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 216 it 122	 PSNR SIDD: 37.4557	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 216 it 163	 PSNR SIDD: 37.4345	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
Epoch: 216	Time: 147.5065	Loss: 1.4852	LearningRate 0.000013
[Ep 217 it 40	 PSNR SIDD: 37.4659	] ----  [best_Ep_SIDD 202 best_it_SIDD 81 Best_PSNR_SIDD 37.4908] 
[Ep 217 it 81	 PSNR SIDD: 37.5029	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
[Ep 217 it 122	 PSNR SIDD: 37.4910	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
[Ep 217 it 163	 PSNR SIDD: 37.4935	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
Epoch: 217	Time: 156.4023	Loss: 1.4911	LearningRate 0.000013
[Ep 218 it 40	 PSNR SIDD: 37.4503	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
[Ep 218 it 81	 PSNR SIDD: 37.4733	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
[Ep 218 it 122	 PSNR SIDD: 37.4681	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
[Ep 218 it 163	 PSNR SIDD: 37.4672	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
Epoch: 218	Time: 145.5339	Loss: 1.4879	LearningRate 0.000013
[Ep 219 it 40	 PSNR SIDD: 37.5007	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
[Ep 219 it 81	 PSNR SIDD: 37.4838	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
[Ep 219 it 122	 PSNR SIDD: 37.4865	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
[Ep 219 it 163	 PSNR SIDD: 37.4998	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
Epoch: 219	Time: 145.7361	Loss: 1.4949	LearningRate 0.000013
[Ep 220 it 40	 PSNR SIDD: 37.4757	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
[Ep 220 it 81	 PSNR SIDD: 37.4841	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
[Ep 220 it 122	 PSNR SIDD: 37.4662	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
[Ep 220 it 163	 PSNR SIDD: 37.4731	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
Epoch: 220	Time: 150.0155	Loss: 1.4970	LearningRate 0.000013
[Ep 221 it 40	 PSNR SIDD: 37.4912	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
[Ep 221 it 81	 PSNR SIDD: 37.4654	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
[Ep 221 it 122	 PSNR SIDD: 37.4725	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
[Ep 221 it 163	 PSNR SIDD: 37.4618	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
Epoch: 221	Time: 145.6981	Loss: 1.5202	LearningRate 0.000013
[Ep 222 it 40	 PSNR SIDD: 37.4811	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
[Ep 222 it 81	 PSNR SIDD: 37.4837	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
[Ep 222 it 122	 PSNR SIDD: 37.4910	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
[Ep 222 it 163	 PSNR SIDD: 37.4765	] ----  [best_Ep_SIDD 217 best_it_SIDD 81 Best_PSNR_SIDD 37.5029] 
Epoch: 222	Time: 147.9615	Loss: 1.4962	LearningRate 0.000013
[Ep 223 it 40	 PSNR SIDD: 37.5032	] ----  [best_Ep_SIDD 223 best_it_SIDD 40 Best_PSNR_SIDD 37.5032] 
[Ep 223 it 81	 PSNR SIDD: 37.4764	] ----  [best_Ep_SIDD 223 best_it_SIDD 40 Best_PSNR_SIDD 37.5032] 
[Ep 223 it 122	 PSNR SIDD: 37.4793	] ----  [best_Ep_SIDD 223 best_it_SIDD 40 Best_PSNR_SIDD 37.5032] 
[Ep 223 it 163	 PSNR SIDD: 37.4918	] ----  [best_Ep_SIDD 223 best_it_SIDD 40 Best_PSNR_SIDD 37.5032] 
Epoch: 223	Time: 154.4696	Loss: 1.4879	LearningRate 0.000013
[Ep 224 it 40	 PSNR SIDD: 37.4662	] ----  [best_Ep_SIDD 223 best_it_SIDD 40 Best_PSNR_SIDD 37.5032] 
[Ep 224 it 81	 PSNR SIDD: 37.4666	] ----  [best_Ep_SIDD 223 best_it_SIDD 40 Best_PSNR_SIDD 37.5032] 
[Ep 224 it 122	 PSNR SIDD: 37.4821	] ----  [best_Ep_SIDD 223 best_it_SIDD 40 Best_PSNR_SIDD 37.5032] 
[Ep 224 it 163	 PSNR SIDD: 37.4859	] ----  [best_Ep_SIDD 223 best_it_SIDD 40 Best_PSNR_SIDD 37.5032] 
Epoch: 224	Time: 147.8941	Loss: 1.5051	LearningRate 0.000013
[Ep 225 it 40	 PSNR SIDD: 37.4848	] ----  [best_Ep_SIDD 223 best_it_SIDD 40 Best_PSNR_SIDD 37.5032] 
[Ep 225 it 81	 PSNR SIDD: 37.5006	] ----  [best_Ep_SIDD 223 best_it_SIDD 40 Best_PSNR_SIDD 37.5032] 
[Ep 225 it 122	 PSNR SIDD: 37.5132	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 225 it 163	 PSNR SIDD: 37.4963	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
Epoch: 225	Time: 154.1420	Loss: 1.4838	LearningRate 0.000013
[Ep 226 it 40	 PSNR SIDD: 37.4913	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 226 it 81	 PSNR SIDD: 37.4870	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 226 it 122	 PSNR SIDD: 37.5006	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 226 it 163	 PSNR SIDD: 37.4914	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
Epoch: 226	Time: 145.7018	Loss: 1.5184	LearningRate 0.000013
[Ep 227 it 40	 PSNR SIDD: 37.4814	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 227 it 81	 PSNR SIDD: 37.4976	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 227 it 122	 PSNR SIDD: 37.4882	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 227 it 163	 PSNR SIDD: 37.4870	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
Epoch: 227	Time: 147.8556	Loss: 1.5060	LearningRate 0.000013
[Ep 228 it 40	 PSNR SIDD: 37.4825	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 228 it 81	 PSNR SIDD: 37.4384	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 228 it 122	 PSNR SIDD: 37.4958	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 228 it 163	 PSNR SIDD: 37.4663	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
Epoch: 228	Time: 146.7916	Loss: 1.4954	LearningRate 0.000013
[Ep 229 it 40	 PSNR SIDD: 37.4990	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 229 it 81	 PSNR SIDD: 37.4622	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 229 it 122	 PSNR SIDD: 37.4945	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 229 it 163	 PSNR SIDD: 37.4432	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
Epoch: 229	Time: 145.8129	Loss: 1.5055	LearningRate 0.000013
[Ep 230 it 40	 PSNR SIDD: 37.4656	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 230 it 81	 PSNR SIDD: 37.4875	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 230 it 122	 PSNR SIDD: 37.4401	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 230 it 163	 PSNR SIDD: 37.4877	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
Epoch: 230	Time: 145.6229	Loss: 1.4986	LearningRate 0.000013
[Ep 231 it 40	 PSNR SIDD: 37.4678	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 231 it 81	 PSNR SIDD: 37.4914	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 231 it 122	 PSNR SIDD: 37.4769	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 231 it 163	 PSNR SIDD: 37.4476	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
Epoch: 231	Time: 145.7637	Loss: 1.5016	LearningRate 0.000013
[Ep 232 it 40	 PSNR SIDD: 37.4896	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 232 it 81	 PSNR SIDD: 37.4428	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 232 it 122	 PSNR SIDD: 37.4943	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 232 it 163	 PSNR SIDD: 37.4215	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
Epoch: 232	Time: 145.5050	Loss: 1.4938	LearningRate 0.000013
[Ep 233 it 40	 PSNR SIDD: 37.4616	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 233 it 81	 PSNR SIDD: 37.4630	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 233 it 122	 PSNR SIDD: 37.4288	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
[Ep 233 it 163	 PSNR SIDD: 37.4955	] ----  [best_Ep_SIDD 225 best_it_SIDD 122 Best_PSNR_SIDD 37.5132] 
Epoch: 233	Time: 150.2277	Loss: 1.4966	LearningRate 0.000013
[Ep 234 it 40	 PSNR SIDD: 37.5176	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 234 it 81	 PSNR SIDD: 37.5038	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 234 it 122	 PSNR SIDD: 37.4843	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 234 it 163	 PSNR SIDD: 37.5037	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
Epoch: 234	Time: 154.1228	Loss: 1.5013	LearningRate 0.000013
[Ep 235 it 40	 PSNR SIDD: 37.4852	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 235 it 81	 PSNR SIDD: 37.5147	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 235 it 122	 PSNR SIDD: 37.4897	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 235 it 163	 PSNR SIDD: 37.4216	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
Epoch: 235	Time: 147.9680	Loss: 1.5057	LearningRate 0.000013
[Ep 236 it 40	 PSNR SIDD: 37.4394	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 236 it 81	 PSNR SIDD: 37.4866	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 236 it 122	 PSNR SIDD: 37.4765	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 236 it 163	 PSNR SIDD: 37.4970	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
Epoch: 236	Time: 145.6734	Loss: 1.5001	LearningRate 0.000013
[Ep 237 it 40	 PSNR SIDD: 37.5068	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 237 it 81	 PSNR SIDD: 37.4904	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 237 it 122	 PSNR SIDD: 37.4872	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 237 it 163	 PSNR SIDD: 37.4722	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
Epoch: 237	Time: 145.5650	Loss: 1.5027	LearningRate 0.000013
[Ep 238 it 40	 PSNR SIDD: 37.4733	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 238 it 81	 PSNR SIDD: 37.5015	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 238 it 122	 PSNR SIDD: 37.4772	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 238 it 163	 PSNR SIDD: 37.4773	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
Epoch: 238	Time: 147.9073	Loss: 1.4817	LearningRate 0.000013
[Ep 239 it 40	 PSNR SIDD: 37.5119	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 239 it 81	 PSNR SIDD: 37.4915	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 239 it 122	 PSNR SIDD: 37.5082	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 239 it 163	 PSNR SIDD: 37.4934	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
Epoch: 239	Time: 152.1539	Loss: 1.4885	LearningRate 0.000013
[Ep 240 it 40	 PSNR SIDD: 37.4837	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 240 it 81	 PSNR SIDD: 37.4855	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 240 it 122	 PSNR SIDD: 37.4752	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 240 it 163	 PSNR SIDD: 37.5019	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
Epoch: 240	Time: 145.7678	Loss: 1.4969	LearningRate 0.000013
[Ep 241 it 40	 PSNR SIDD: 37.4617	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 241 it 81	 PSNR SIDD: 37.5044	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 241 it 122	 PSNR SIDD: 37.5075	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 241 it 163	 PSNR SIDD: 37.5104	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
Epoch: 241	Time: 145.6234	Loss: 1.4905	LearningRate 0.000013
[Ep 242 it 40	 PSNR SIDD: 37.5146	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 242 it 81	 PSNR SIDD: 37.4979	] ----  [best_Ep_SIDD 234 best_it_SIDD 40 Best_PSNR_SIDD 37.5176] 
[Ep 242 it 122	 PSNR SIDD: 37.5294	] ----  [best_Ep_SIDD 242 best_it_SIDD 122 Best_PSNR_SIDD 37.5294] 
[Ep 242 it 163	 PSNR SIDD: 37.5141	] ----  [best_Ep_SIDD 242 best_it_SIDD 122 Best_PSNR_SIDD 37.5294] 
Epoch: 242	Time: 156.1387	Loss: 1.4843	LearningRate 0.000013
[Ep 243 it 40	 PSNR SIDD: 37.4966	] ----  [best_Ep_SIDD 242 best_it_SIDD 122 Best_PSNR_SIDD 37.5294] 
[Ep 243 it 81	 PSNR SIDD: 37.5239	] ----  [best_Ep_SIDD 242 best_it_SIDD 122 Best_PSNR_SIDD 37.5294] 
[Ep 243 it 122	 PSNR SIDD: 37.5305	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
[Ep 243 it 163	 PSNR SIDD: 37.5101	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
Epoch: 243	Time: 152.1592	Loss: 1.4951	LearningRate 0.000013
[Ep 244 it 40	 PSNR SIDD: 37.4952	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
[Ep 244 it 81	 PSNR SIDD: 37.5254	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
[Ep 244 it 122	 PSNR SIDD: 37.5241	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
[Ep 244 it 163	 PSNR SIDD: 37.5294	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
Epoch: 244	Time: 145.7479	Loss: 1.5003	LearningRate 0.000013
[Ep 245 it 40	 PSNR SIDD: 37.4858	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
[Ep 245 it 81	 PSNR SIDD: 37.4966	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
[Ep 245 it 122	 PSNR SIDD: 37.5181	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
[Ep 245 it 163	 PSNR SIDD: 37.4647	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
Epoch: 245	Time: 145.6212	Loss: 1.5007	LearningRate 0.000013
[Ep 246 it 40	 PSNR SIDD: 37.5113	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
[Ep 246 it 81	 PSNR SIDD: 37.5155	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
[Ep 246 it 122	 PSNR SIDD: 37.5221	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
[Ep 246 it 163	 PSNR SIDD: 37.5184	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
Epoch: 246	Time: 145.5994	Loss: 1.4910	LearningRate 0.000013
[Ep 247 it 40	 PSNR SIDD: 37.4947	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
[Ep 247 it 81	 PSNR SIDD: 37.5084	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
[Ep 247 it 122	 PSNR SIDD: 37.5114	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
[Ep 247 it 163	 PSNR SIDD: 37.5066	] ----  [best_Ep_SIDD 243 best_it_SIDD 122 Best_PSNR_SIDD 37.5305] 
Epoch: 247	Time: 147.8549	Loss: 1.4848	LearningRate 0.000013
[Ep 248 it 40	 PSNR SIDD: 37.5321	] ----  [best_Ep_SIDD 248 best_it_SIDD 40 Best_PSNR_SIDD 37.5321] 
[Ep 248 it 81	 PSNR SIDD: 37.5369	] ----  [best_Ep_SIDD 248 best_it_SIDD 81 Best_PSNR_SIDD 37.5369] 
[Ep 248 it 122	 PSNR SIDD: 37.5120	] ----  [best_Ep_SIDD 248 best_it_SIDD 81 Best_PSNR_SIDD 37.5369] 
[Ep 248 it 163	 PSNR SIDD: 37.5206	] ----  [best_Ep_SIDD 248 best_it_SIDD 81 Best_PSNR_SIDD 37.5369] 
Epoch: 248	Time: 162.4912	Loss: 1.4992	LearningRate 0.000013
[Ep 249 it 40	 PSNR SIDD: 37.4840	] ----  [best_Ep_SIDD 248 best_it_SIDD 81 Best_PSNR_SIDD 37.5369] 
[Ep 249 it 81	 PSNR SIDD: 37.4967	] ----  [best_Ep_SIDD 248 best_it_SIDD 81 Best_PSNR_SIDD 37.5369] 
[Ep 249 it 122	 PSNR SIDD: 37.4824	] ----  [best_Ep_SIDD 248 best_it_SIDD 81 Best_PSNR_SIDD 37.5369] 
[Ep 249 it 163	 PSNR SIDD: 37.5346	] ----  [best_Ep_SIDD 248 best_it_SIDD 81 Best_PSNR_SIDD 37.5369] 
Epoch: 249	Time: 145.7570	Loss: 1.4834	LearningRate 0.000003
[Ep 250 it 40	 PSNR SIDD: 37.5033	] ----  [best_Ep_SIDD 248 best_it_SIDD 81 Best_PSNR_SIDD 37.5369] 
[Ep 250 it 81	 PSNR SIDD: 37.5458	] ----  [best_Ep_SIDD 250 best_it_SIDD 81 Best_PSNR_SIDD 37.5458] 
[Ep 250 it 122	 PSNR SIDD: 37.5374	] ----  [best_Ep_SIDD 250 best_it_SIDD 81 Best_PSNR_SIDD 37.5458] 
[Ep 250 it 163	 PSNR SIDD: 37.5360	] ----  [best_Ep_SIDD 250 best_it_SIDD 81 Best_PSNR_SIDD 37.5458] 
Epoch: 250	Time: 152.0393	Loss: 1.4806	LearningRate 0.000006
